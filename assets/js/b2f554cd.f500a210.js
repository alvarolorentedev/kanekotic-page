"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/psycological-safety-in-software-developmente","metadata":{"permalink":"/blog/psycological-safety-in-software-developmente","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/psycological-safety-in-software-developmente.md","source":"@site/blog/psycological-safety-in-software-developmente.md","title":"Psycological safety in software development","description":"What are some succes factor of high performing teams and organizations? One undoubtedly is the ability to share and exchange without fear or shame ","date":"2023-01-26T20:41:30.000Z","formattedDate":"January 26, 2023","tags":[{"label":"programming","permalink":"/blog/tags/programming"},{"label":"productivity","permalink":"/blog/tags/productivity"},{"label":"motivation","permalink":"/blog/tags/motivation"}],"readingTime":1.97,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"authors":"kanekotic","draft":false,"title":"Psycological safety in software development","description":"What are some succes factor of high performing teams and organizations? One undoubtedly is the ability to share and exchange without fear or shame ","tags":["programming","productivity","motivation"],"published":"2023-01-27T00:00:00.000Z","canonical_url":"","cover_image":"","series":"Whwt makes high performing teams "},"nextItem":{"title":"Double-edge Microservices: APIs the New Singleton","permalink":"/blog/2022/12/19/api-singleton"}},"content":"psychological safety is essential for the success of software development teams. By fostering open communication and encouraging a culture of learning and innovation, teams can work more efficiently, effectively and creatively. By promoting psychological safety, managers and leaders can help their team members to reach their full potential and take the team to the next level.\\n\\n## Long Version\\n\\n### What is psicological safety\\n\\n> Psychological safety refers to the belief that one will not be punished or humiliated for speaking up with ideas, questions, concerns or mistakes. It is a shared belief held by members of a team that the team is safe for interpersonal risk-taking. This safety allows team members\\n\\n### Why is psicological safety important\\n\\nPsychological safety is an essential aspect of any successful organization. Software development organizations are no exception.\\n\\nOne of the main benefits of psychological safety is the ability to foster open and honest communication. When team members feel safe to speak up, they are more likely to share their thoughts and ideas, which can lead to more efficient problem-solving and decision-making. In a field that is constantly evolving and where new technologies and approaches are continually emerging, it is essential to stay up-to-date and adapt to change.\\n\\nFurthermore, it allows for creativity and innovation to flourish. When team members feel secure in their ability to express themselves, they are more likely to think outside the box and come up with new and unique solutions. In software development this can be the diference in between the success and failure of a project or a huge diference in ROI.\\n\\nHowever, creating a culture of psychological safety is not always easy. It requires active effort and commitment from everyone on the team, including managers and leaders. One important step is to actively listen to and encourage open dialogue among team members. Managers should also create an environment where mistakes are viewed as opportunities for learning, not as failures.\\n\\nAnother important step is to establish clear guidelines and expectations for communication and behavior within the team. This can include things like setting ground rules for respectful dialogue, and providing training on active listening and conflict resolution.\\n\\nFinally, it is essential to hold everyone on the team accountable for maintaining a culture of psychological safety. This includes managers, who should lead by example and model the behavior they expect from their team."},{"id":"/2022/12/19/api-singleton","metadata":{"permalink":"/blog/2022/12/19/api-singleton","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-12-19-api-singleton.md","source":"@site/blog/2022-12-19-api-singleton.md","title":"Double-edge Microservices: APIs the New Singleton","description":"In the current world of development we solve all with APIs, is it becoming an overused practice?","date":"2022-12-19T00:00:00.000Z","formattedDate":"December 19, 2022","tags":[{"label":"webdev","permalink":"/blog/tags/webdev"},{"label":"api","permalink":"/blog/tags/api"},{"label":"architecture","permalink":"/blog/tags/architecture"},{"label":"programming","permalink":"/blog/tags/programming"}],"readingTime":2.27,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Double-edge Microservices: APIs the New Singleton","description":"In the current world of development we solve all with APIs, is it becoming an overused practice?","authors":"kanekotic","tags":["webdev","api","architecture","programming"],"draft":false,"published":"2022-12-20T13:00:00.000Z","series":"microservices a double-edged sword","cover_image":"https://www.kanekotic.com/img/captura-de-pantalla-2022-12-19-a-las-17-16-39.png","canonical_url":"https://www.kanekotic.com/blog/2022/12/19/api-singleton"},"prevItem":{"title":"Psycological safety in software development","permalink":"/blog/psycological-safety-in-software-developmente"},"nextItem":{"title":"Double-edge Microservices: Macro Infrastructure due to Microservice Obsession","permalink":"/blog/2022/12/19/macroInfrastructure-microservice-obsesion"}},"content":"The singleton pattern has got a bad reputation over the years due to be widely overused in the incorrect use cases. With the proliferation of microservices, **have APIs become the new singleton?**\\n\\n## The Problem\\n\\nAPIs, or application programming interfaces, have become a ubiquitous part of modern software development. They allow different systems and applications to communicate with one another, enabling the creation of complex, interconnected systems that can share data and functionality. However, there has been a growing concern that APIs are being overused, leading to a proliferation of unnecessarily complex and fragile systems that are difficult to maintain and scale.\\n\\nOne reason for the perceived overuse of APIs is the ease with which they can be implemented. With the abundance of API management tools and frameworks available, it is relatively straightforward to expose a set of functionality as an API and make it available to other systems. This has led to a proliferation of APIs, many of which are redundant or unnecessary, adding unnecessary complexity to the overall system.\\n\\nAnother issue is the lack of standardization in the API ecosystem. Each API is typically designed to meet the specific needs of the system it was created for, resulting in a wide variety of different designs and conventions. This can make it difficult for developers to understand and use APIs from other systems, as they may have to learn and adapt to new conventions and patterns each time they encounter a new API.\\n\\nIn addition to these issues, the reliance on APIs can also lead to fragile systems that are difficult to maintain and scale. When multiple systems are tightly coupled through APIs, a change to one system can have cascading effects on others, leading to unexpected behavior and potential failures. This can make it difficult to make changes or updates to a system without the risk of breaking something else.\\n\\nThere are also concerns about the security of APIs. As they allow systems to communicate with one another, they can also provide a potential entry point for attackers to gain access to sensitive data or functionality. Properly securing APIs can be a complex and time-consuming task, and if not done correctly, can lead to significant vulnerabilities.\\n\\n## The Solution\\n\\nSo, what can be done to address these issues? One solution is to use APIs more judiciously, carefully evaluating whether an API is truly necessary before implementing it. This can help reduce the overall complexity of the system and make it easier to maintain and scale. \\n\\nIt\'s also important to adopt API design standards and guidelines, which can help ensure that APIs are consistent and easy to understand and use. Finally, proper API security practices should be implemented to protect against potential vulnerabilities."},{"id":"/2022/12/19/macroInfrastructure-microservice-obsesion","metadata":{"permalink":"/blog/2022/12/19/macroInfrastructure-microservice-obsesion","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-12-19-macroInfrastructure-microservice-obsesion.md","source":"@site/blog/2022-12-19-macroInfrastructure-microservice-obsesion.md","title":"Double-edge Microservices: Macro Infrastructure due to Microservice Obsession","description":"Macro Infrastructure due to Microservice Obsession the over-engineering of our age","date":"2022-12-19T00:00:00.000Z","formattedDate":"December 19, 2022","tags":[{"label":"webdev","permalink":"/blog/tags/webdev"},{"label":"api","permalink":"/blog/tags/api"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":3.495,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Double-edge Microservices: Macro Infrastructure due to Microservice Obsession","description":"Macro Infrastructure due to Microservice Obsession the over-engineering of our age","authors":"kanekotic","tags":["webdev","api","programming","architecture"],"draft":false,"published":"2022-12-27T01:00:00.000Z","series":"microservices a double-edged sword","canonical_url":"https://www.kanekotic.com/blog/2022/12/19/macroInfrastructure-microservice-obsesion","cover_image":"https://www.kanekotic.com/img/captura-de-pantalla-2022-12-19-a-las-17-17-49.png"},"prevItem":{"title":"Double-edge Microservices: APIs the New Singleton","permalink":"/blog/2022/12/19/api-singleton"},"nextItem":{"title":"TDD is not called TDT for a reason","permalink":"/blog/2022/11/24/tdd-is-not-called-tdt-for-a-reason"}},"content":"## The Context\\n\\nCloud and infrastructure as code have revolutionized our industry. They allowed us to be able to procure infrastructure in a simple, adaptable way.  \\nThis allowed us to move from writing huge monolithic applications to write microservices that interact between them.  \\nOne of the most accepted definition of a microservice can be expressed as:\\n\\n> A self-contained portion of code that does not share resources with other services, can be deployed independently, and should be easy to rewrite in a small portion of time.\\n\\nThis sounds great when we talk about individual parts of a software projects. Nevertheless, when thinking about systems and how they operate, There is a point to make about granularity as software does never work fully isolated. It requires interactions with other systems to fulfill their purpose.\\n\\nMost of the monolithic applications of the past had an issue of being over-engineered to allow changes that might never happen.\\n\\nCould that also happen with microservices?\\n\\n## The Issues\\n\\n### Clarity Of The Domain\\n\\nWhen a system grows too much in small pieces, it becomes more and more complex to understand the big picture.  \\nWhen pieces are too small, domain events start becoming exchange of information in between nodes of a network. All this removes cohesion on the knowledge over the domain of a system, making it difficult to grasp the real intention and capabilities of concepts and actors across a system.\\n\\n### Babel tower Issue\\n\\nThe more parts a system has, the less heterogeneous it becomes. This at the same time translates into a more complex environment with more integrations, frameworks and bigger learning curves that affects delivery. There need to be a balance of when and where in a system a new technology is added. Decisions must be based on needs and not on preferences.\\n\\n### Implicit runtime dependencies\\n\\nThe more a system get split, the more dependency on certain node it will have. This tends to cause more dependencies in between the pieces of your infrastructure-based puzzle where you start having god infrastructure points that become single point of failure, or you have a chain of dependent infra that need to be deployed in a go or certain order.\\n\\n### Hidden Complexity\\n\\nThe more your microservice environment grows, the more it requires a growing support infrastructure for monitoring, alerting and other services not used as part of the main system. This normally is a separate effort which has its cost. The more a system grows, those hidden complexities become a dependency for all the nodes in the system, making it a complex task to evolve and change those dependencies.\\n\\n### Why\u2026 if YAGNI\\n\\nOne of the main ideas of microservices was to be able to validate assumptions fast. Before bootstrapping new services or infrastructure, there is a need to ask ourselves about the existence of a service or infrastructure that contains the domain knowledge required for the experiment in the current ecosystem. If we are not careful, experiments won\'t be experiments. They will be MVPs, where domain knowledge is re-implemented, just for having it as a standalone node on the system.\\n\\n### Repeating Yourself\\n\\nWhen we create pieces of code that are independent, there is always a certain level of bootstrapping that is required and repeated in each node of our systems. This will cause not only a set of duplicated code, but also has a development time cost attached to it. Bootstrapping a project in a high granularity system can be complex to standardize.\\n\\nMicroservices, the cloud, and infrastructure as a service have definitely revolutionized our industry, nevertheless as in everything there is a need for balance. Making sure we use the right tool for the job, and we don\'t over-engineer things, not only at a code level but also at infrastructure level, as everything has a cost.\\n\\n## Conclusion\\n\\nIn conclusion, a macro infrastructure due to microservice obsession can lead to increased complexity and overhead costs, as well as challenges in making changes and updates to the system. While microservices can offer benefits such as increased scalability and flexibility, it is important for organizations to carefully consider their specific needs and choose the right level of granularity for their architecture."},{"id":"/2022/11/24/tdd-is-not-called-tdt-for-a-reason","metadata":{"permalink":"/blog/2022/11/24/tdd-is-not-called-tdt-for-a-reason","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-11-24-tdd-is-not-called-tdt-for-a-reason.md","source":"@site/blog/2022-11-24-tdd-is-not-called-tdt-for-a-reason.md","title":"TDD is not called TDT for a reason","description":"When people elaborate on TDD they seem to stay focused on the first letter but miss the focus of the other two letters. ","date":"2022-11-24T00:00:00.000Z","formattedDate":"November 24, 2022","tags":[{"label":"webdev","permalink":"/blog/tags/webdev"},{"label":"testing","permalink":"/blog/tags/testing"},{"label":"architecture","permalink":"/blog/tags/architecture"},{"label":"programming","permalink":"/blog/tags/programming"}],"readingTime":1.575,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"authors":"kanekotic","draft":false,"title":"TDD is not called TDT for a reason","description":"When people elaborate on TDD they seem to stay focused on the first letter but miss the focus of the other two letters. ","tags":["webdev","testing","architecture","programming"],"published":"2022-11-28T03:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/11/24/tdd-is-not-called-tdt-for-a-reason","cover_image":"https://www.kanekotic.com/img/tdd.png","series":""},"prevItem":{"title":"Double-edge Microservices: Macro Infrastructure due to Microservice Obsession","permalink":"/blog/2022/12/19/macroInfrastructure-microservice-obsesion"},"nextItem":{"title":"Delivery Acceleration: Parallel Changes Strategy","permalink":"/blog/2022/10/14/delivery-acceleration-parallel-changes-strategy"}},"content":"I have observed quite a few articles lately that elaborate on issues with TDD. Nevertheless, they focused on the first letter but miss the focus of the other two letters.\\n\\n## Not A Testing Strategy\\n\\nIf you take anything out of this article, please think about this quote:\\n\\n> If TDD was about testing it would have been called TDT (test driven testing).\\n\\nThe fact that we do test upfront in TDD does not mean at all that there is a direct relationship with a testing strategy, and as many preach, unit testing is not enough to create robust software.\\n\\n## A Design Strategy\\n\\nTDD is actually a **Design Strategy**, this is why the 2 last letter are for **driven development**. This means that your final code is being moved by those tests and not the other way around.\\n\\nThe design that TDD will move you towards to is **minimalistic**. Reducing the tendency of overengineering solutions when you don\'t need them. This brings a **reducing time to market**, by reducing the **accidental complexity**.\\n\\nWhen doing TDD most developers have the complexity of letting go their **egos**, the problem when people fight against the practices is because they think to know better. Nevertheless, it tends to **generate waste** because most code optimizations tend to be premature and most extensibility points will never be modified.\\n\\nThere are places where TDD does not fit, for example while investigating a technology through a spike or PoC because in these cases, the person is exploring knowledge not generating value. In other cases, TDD allows you to bring value in the shortest way possible.\\n\\n## Conclusion\\n\\nIf you are an experienced developer, do not discard TDD because you think you know better, allow it to challenge you. If you are a new developer, learn from the different ways of doing things and understand the value, don\'t take articles at face value."},{"id":"/2022/10/14/delivery-acceleration-parallel-changes-strategy","metadata":{"permalink":"/blog/2022/10/14/delivery-acceleration-parallel-changes-strategy","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-10-14-delivery-acceleration-parallel-changes-strategy.md","source":"@site/blog/2022-10-14-delivery-acceleration-parallel-changes-strategy.md","title":"Delivery Acceleration: Parallel Changes Strategy","description":"Code evolve and changes. Making sure we don\'t break things in a continuous deployment environment.","date":"2022-10-14T00:00:00.000Z","formattedDate":"October 14, 2022","tags":[{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":1.53,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"authors":"kanekotic","draft":false,"title":"Delivery Acceleration: Parallel Changes Strategy","description":"Code evolve and changes. Making sure we don\'t break things in a continuous deployment environment.","tags":["softwaredevelopment","programming","devops","productivity"],"published":"2022-11-07T00:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/10/14/delivery-acceleration-parallel-changes-strategy","cover_image":"https://www.kanekotic.com/img/expand_contract.jpeg","series":"Accelerate Continious Integration & Delivery Practices"},"prevItem":{"title":"TDD is not called TDT for a reason","permalink":"/blog/2022/11/24/tdd-is-not-called-tdt-for-a-reason"},"nextItem":{"title":"Delivery Acceleration: Version Control Integration Strategy","permalink":"/blog/2022/10/12/delivery-acceleration-version-control-integration-strategy"}},"content":"As we develop a product over time, changes need to be made as we need to accommodate new functionality. As most of our systems don\'t run isolated, and we have clients that used them (ex. public API), We have to keep compatibility at least on a temporary basis. How do we achieve this?\\n\\n## Versions\\n\\nA common practice is to have different versions for the multiple clients. While simple, it also requires significant effort to maintain as whenever an issue or bug is spotted, multiple places are affected, meaning there are more possibility of side effects.  \\nIt also makes it more difficult to make a case for clients to migrate from one to the other due to the contract changes.\\n\\n![](https://www.kanekotic.com/img/version.png)\\n\\nThis affect mostly negatively the next DORA 4 metrics:\\n\\n* \u274c **Lead Time for change**\\n\\n## Versionless: Expand & Contract\\n\\nAs the name says, this strategy intents to have only one state of truth and not a multitude of them. Versionless has been heavily adopted as a principle by GraphQL, for example.  \\nWe can achieve this in any code base by implementing a strategy for parallel changes called **Expand & Contract**, it\'s call this way due to the phases code goes through. Let\'s see for example we want to migrate from using one field value to a similar field with a more complex representation.\\n\\n* **Expand**: We add the new \'field\' to the existing contract, and add the code to support this strategy on the existing code.\\n* **Contract**: We monitor the usage of the old \'field\' to understand when it is possible to deprecate, at that point we remove the old code.\\n\\n![](https://www.kanekotic.com/img/expand_contract.jpeg)\\n\\nWith this, we have a clean source code that we can evolve indefinitely as required by the business.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Lead Time for change**"},{"id":"/2022/10/12/delivery-acceleration-version-control-integration-strategy","metadata":{"permalink":"/blog/2022/10/12/delivery-acceleration-version-control-integration-strategy","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-10-12-delivery-acceleration-version-control-integration-strategy.md","source":"@site/blog/2022-10-12-delivery-acceleration-version-control-integration-strategy.md","title":"Delivery Acceleration: Version Control Integration Strategy","description":"How do you integrate code in the team matters, it will directly affect the rest of your architecture and practices like we have seen in previous chapters","date":"2022-10-12T00:00:00.000Z","formattedDate":"October 12, 2022","tags":[{"label":"productivity","permalink":"/blog/tags/productivity"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"}],"readingTime":2.54,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"authors":"kanekotic","draft":false,"title":"Delivery Acceleration: Version Control Integration Strategy","description":"How do you integrate code in the team matters, it will directly affect the rest of your architecture and practices like we have seen in previous chapters","tags":["productivity","devops","programming","softwaredevelopment"],"published":"2022-10-31T00:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/10/12/delivery-acceleration-version-control-integration-strategy","cover_image":"https://www.kanekotic.com/img/trunk.png","series":"Accelerate Continious Integration & Delivery Practices"},"prevItem":{"title":"Delivery Acceleration: Parallel Changes Strategy","permalink":"/blog/2022/10/14/delivery-acceleration-parallel-changes-strategy"},"nextItem":{"title":"Delivery Acceleration: Testing & Validation","permalink":"/blog/2022/10/11/delivery-acceleration-testing-validation"}},"content":"I have already written some [other post](https://www.kanekotic.com/blog/2022/08/08/stop-prs) on this topic. I will go straight to the point on comparing Git Flow (a [legacy strategy](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow) that most companies use) and Trunk-Based Development.\\n\\n## Gitflow: The Bad & The Ugly\\n\\nWhy do I call it the bad and the ugly? Because it does not allow you to achieve Continuous Deployment.  \\nThe idea is that every developer works isolated on their branch, validate on their branch and ask through a merge request to add their code to the X stage branch.\\n\\n![](https://www.kanekotic.com/img/gitflow-diagram-768x973.png)  \\nThere are multiple issues with this:\\n\\n* Code does not exist isolated, we don\'t deploy isolated code, so the isolated test is not valid as it will require retesting.\\n* The peer review process happens at the end, causing a very slow feedback loop. Having to rewrite code that could be avoided.\\n* The more time the branch lives, the more it diverges from the original behavior and the more complex it is to merge.\\n* Merging can cause complex conflicts that require revalidation, and it might have side effect in other features. \\n* As there needs to be validations of the merges, it\'s normal to have multiple environments that give a false sense of security, increases the $ cost and increases the lead time.\\n* Egos and preferences become part of the review process, as it has become an \'accepted\' practice that the \'experts\' or \'leads\' do the reviews.\\n\\nAll of this is red tape to go through is a problem that makes delivery slower, and create a lack of ownership mentality farther away from what happen to the individual branch.\\n\\n  \\nThis affects mostly negatively, most of DORA 4 metrics:\\n\\n* \u274c **Deployment frequency**\\n* \u274c **Lead Time for change**\\n* \u274c **Mean Time To Recovery**\\n\\nIs there a simpler and better way to collaborate on code way?\\n\\n## Trunk-Based Development: The Good\\n\\nWhat happens if we all commit to the same branch.\\n\\n![](https://www.kanekotic.com/img/trunk.png)\\n\\nMost of the expressed issues are solved, in this scenario by:\\n\\n* Code is never isolated, as we all push code to the same place.\\n* Teams that do this practices also practice pair programming, making the peer review process is continuous and synchronous.\\n* As individuals push multiple times a day, merge conflicts are non-existent or small.\\n* Does not require revalidation, as validation is a continuous stream in the single environment.\\n* No ego environment tent to appear as there is no centralize approver of code, so it\'s not a matter of preference but a team effort and ownership.\\n\\nAs we have seen before, having unfinished code does not need to affect users, as it is common practice to use feature flags and/or branching by abstraction.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n\\n## Conclusion\\n\\nSimplicity is king. Having a simpler structure enables speed and quality of delivery, as it allow teams to work closely, take shared ownership and act faster related to a smaller change."},{"id":"/2022/10/11/delivery-acceleration-testing-validation","metadata":{"permalink":"/blog/2022/10/11/delivery-acceleration-testing-validation","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-10-11-delivery-acceleration-testing-validation.md","source":"@site/blog/2022-10-11-delivery-acceleration-testing-validation.md","title":"Delivery Acceleration: Testing & Validation","description":"is testing enough to make sure our code works?","date":"2022-10-11T00:00:00.000Z","formattedDate":"October 11, 2022","tags":[{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":1.215,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Delivery Acceleration: Testing & Validation","description":"is testing enough to make sure our code works?","authors":["kanekotic"],"tags":["softwaredevelopment","programming","devops","productivity"],"published":"2022-10-23T23:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/10/11/delivery-acceleration-testing-validation","cover_image":"https://www.kanekotic.com/img/testing.jpg","series":"Accelerate Continious Integration & Delivery Practices"},"prevItem":{"title":"Delivery Acceleration: Version Control Integration Strategy","permalink":"/blog/2022/10/12/delivery-acceleration-version-control-integration-strategy"},"nextItem":{"title":"Delivery Acceleration: Enabling Features","permalink":"/blog/2022/10/10/delivery-acceleration-enabling-features"}},"content":"Before we enable code for our clients, we need to test and validate it does what is expected. This could be an entire series of its own (please let me know if you want one), so I will keep it on a high level.\\n\\n## Testing\\n\\nI could probably spend hours sharing different types of testing strategies and where and why to use them.  \\nIn reality, the most important thing, is to make sure we use the correct ratio of the different types of tests, as it will highly affect the time and location of your testing.\\n\\nThis ratio has always been shown as a pyramid with:\\n\\n* **Unit test**: validate individual pieces of logic that are isolated.\\n* **Integration test**: validates interactions with multiple parts of your system or other systems.\\n* **Integrated test**: They test the system as a whole.\\n\\n![](https://www.kanekotic.com/img/pyramid.jpeg)\\n\\nTests are divided in these layers because there is a cost in time and complexity.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Change Failure Rate**\\n\\n## Validation\\n\\nValidation differs from testing as it\'s the confirmation that the behavior is what the user expected, for now, humans are the only ones that can discern this.  \\nAs we have seen in the previous chapter, the recommendation is to do this in production, so you get:\\n\\n* Get real behaviors of interactions with other systems\\n* Get real performance\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Change Failure Rate**"},{"id":"/2022/10/10/delivery-acceleration-enabling-features","metadata":{"permalink":"/blog/2022/10/10/delivery-acceleration-enabling-features","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-10-10-delivery-acceleration-enabling-features.md","source":"@site/blog/2022-10-10-delivery-acceleration-enabling-features.md","title":"Delivery Acceleration: Enabling Features","description":"How do we roll out features? What are some practices that can save us from the big bang release","date":"2022-10-10T00:00:00.000Z","formattedDate":"October 10, 2022","tags":[{"label":"productivity","permalink":"/blog/tags/productivity"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"}],"readingTime":2.635,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Delivery Acceleration: Enabling Features","description":"How do we roll out features? What are some practices that can save us from the big bang release","authors":"kanekotic","tags":["productivity","devops","programming","softwaredevelopment"],"published":"2022-10-16T22:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/10/10/delivery-acceleration-enabling-features","cover_image":"https://www.kanekotic.com/img/toggles.jpeg","series":"Accelerate Continious Integration & Delivery Practices"},"prevItem":{"title":"Delivery Acceleration: Testing & Validation","permalink":"/blog/2022/10/11/delivery-acceleration-testing-validation"},"nextItem":{"title":"Delivery Acceleration: Deployment Environments","permalink":"/blog/2022/10/10/delivery-acceleration-environments"}},"content":"Now that we know where our code lives, we need to make sure our users get access to the features. For this, we need to get our code to the environment we want to deploy to, and control the rollout (if you are not a big bang release fan).\\n\\n## Blue/Green Deployment: Getting to prod with 0 downtime\\n\\nWhat is this?, The concept is simple, we have a set of machines (ex. blue) where we currently have our app running, and we want to deploy. The intent is to create a new set of machines (ex. green) where our new version of the code will run. We would like to validate as much as possible (ex. automated e2e tests) that this new version is up to par with the previous one before moving the traffic and destroy the previous version.\\n\\nYou can see the process in the next graph:\\n\\n![](https://www.kanekotic.com/img/blue_green.jpeg)\\n\\nWith this, we are trying to achieve a 0 downtime while deploying a new version of our code. This is critical for teams that practice continuous deployment, as you want to avoid having systems down as you deploy multiple times a day.\\n\\n## Enabling feature access to users\\n\\nthere are multiple ways to enable access to users, in between them:\\n\\n### Big Bang Releases\\n\\nThis is the plug and pray solution. Pushing the code and expecting it to work as it\'s enabled for all users. This is a very dangerous strategy as your blast radius is all your users.\\n\\n### Canary Releases\\n\\nThis is a practice that comes from the mining industry, The idea was the next one:\\n\\n> If a canary is in the same place where humans are inside the mine, when there is a problem with the breathable air it will be the first one to perish.\\n\\nIf we translate this to software, the idea is to have deployed the changes only to one or a few servers. With this, we can monitor this canary instances and act if any issue happens, we reduce the blast radius of issues to only the users who go through that server.\\n\\n![](https://www.kanekotic.com/img/canary.jpeg)\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Change Failure Rate**\\n\\nThis approach provides us a way to reduce the blast radius from a big bang release. Nevertheless, it does not help us to prevent or act faster upon a bug in our code. \\n\\n### Feature Flag Releases\\n\\nTo improve upon the canary release strategy, we can move towards feature flags.\\n\\nFeature Flags are hiding our code behind a \'flag\' this can help decide if the code is enabled or disabled, as in the next image.\\n\\n![](https://www.kanekotic.com/img/toggles.jpeg)\\n\\nThere are a multitude of services, libraries & SDKs that allow you to create flags in your code. They help by:\\n\\n*  Decouple activation of features from the release pipeline.\\n* Solving incidents in a matter of seconds.\\n* Do a controlled rollout. For example:\\n  * Enable only for team.\\n  * Enable for X% of the traffic.\\n  * Enable for users in a specific country.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u2714\ufe0f **Change Failure Rate**"},{"id":"/2022/10/10/delivery-acceleration-environments","metadata":{"permalink":"/blog/2022/10/10/delivery-acceleration-environments","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-10-10-delivery-acceleration-environments.md","source":"@site/blog/2022-10-10-delivery-acceleration-environments.md","title":"Delivery Acceleration: Deployment Environments","description":"Where should we run our services? are there hidden consts on certain practices?","date":"2022-10-10T00:00:00.000Z","formattedDate":"October 10, 2022","tags":[{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"productivity","permalink":"/blog/tags/productivity"},{"label":"devops","permalink":"/blog/tags/devops"}],"readingTime":2.76,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Delivery Acceleration: Deployment Environments","description":"Where should we run our services? are there hidden consts on certain practices?","authors":"kanekotic","tags":["softwaredevelopment","programming","productivity","devops"],"published":"2022-10-11T23:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/09/10/delivery-acceleration-environments","cover_image":"https://www.kanekotic.com/img/cicd.png","series":"Accelerate Continious Integration & Delivery Practices"},"prevItem":{"title":"Delivery Acceleration: Enabling Features","permalink":"/blog/2022/10/10/delivery-acceleration-enabling-features"},"nextItem":{"title":"Delivery Acceleration: Observability","permalink":"/blog/2022/09/27/delivery-acceleration-observability"}},"content":"Our services need to run somewhere, so our users can access it. It\'s a very common practices to have multiple environments like dev, staging, and prod. Is this actually a good practices?\\n\\n## CI vs. CD vs. CD\\n\\nwhen people talk about continuous integration, delivery and deployment, they normally talk about it as a whole.\\n\\nNevertheless, let\'s reflect why these are 3 different practices. As they are steps in a journey, you can do one and not the next one.\\n\\n![](https://www.kanekotic.com/img/cicd.png)\\n\\n* Continuous integration: allows making reproducible states of the code in multiple places.\\n* Continuous Delivery: Now that it\'s reproducible, it needs to be marked as potentially deployable and provide the ability to deploy it.\\n* Continuous Deployment: Delivers the code to your clients and not only to your team as you commit.\\n\\n## The trap of Multiple Environments\\n\\nAs you can imagine, with the previous definition of CI/CD, having multiple environments will never allow you to achieve Continuous Deployment.\\n\\n![](https://www.kanekotic.com/img/environments.jpeg)\\n\\nThe intent of having multiple environments is to reduce change failure rate, are we actually achieving this with the practices? The answer is normally not due to:\\n\\n* A non-production environment will never be the same as a production.\\n  * Different data\\n  * Different performance\\n  * Different security practices\\n  * Etc\u2026\\n* Stress and ownership of moving things to production\\n* Accumulation of code in lower environments (meaning more bugs).\\n* Longer feedback loop.\\n* Continuous misalignment due to development cycles in between different teams.\\n\\nAs you can see, this makes a fake sense of safety, but it does not affect positively the change failure rate.\\n\\nThis affects mostly negatively, most of DORA 4 metrics:\\n\\n* \u274c **Deployment frequency**\\n* \u274c **Lead Time for change**\\n* \u274c **Mean Time To Recovery**\\n* \u3030\ufe0f **Change Failure Rate**\\n\\n## Achieving Continuous Deployment, Only prod, is it so crazy?\\n\\nHow can a team Continuous deployment? The answer tends to be simple, making every commit go to production and testing in it.  \\nBe aware this does not mean to have our users experience possible bugs or see test data, as we can hide functionalities behind toggles, headers, or parameters that allow access to only the development team. As we will see in future installments of this series.\\n\\nAn example strategy is the one in the next diagram.\\n\\n![](https://www.kanekotic.com/img/single_environment.jpeg)\\n\\nThis allows us to keep only one environment that discriminates in between test and non-test data that can be clean periodically, while it provides the real environment with the real behavior. With this, we solved:\\n\\n* Real performance & behavior.\\n* Continuous alignment with other teams.\\n* Smaller feedback cycles.\\n* Control of rollout.\\n* Smaller $ cost.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u3030\ufe0f **Change Failure Rate**\\n\\n## Conclusion\\n\\nThere is no one size fit all, but modern practices tend to go towards simplicity and fast feedback loops. There are many practices involved on this simplicity that enables us to feel comfortable with only production environments. We will talk about them on this series.   \\n  \\n## Related Videos\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/UBtiBA5QTEg\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\" allowfullscreen></iframe>\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/9C0efJkT0Hg\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\" allowfullscreen></iframe>"},{"id":"/2022/09/27/delivery-acceleration-observability","metadata":{"permalink":"/blog/2022/09/27/delivery-acceleration-observability","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-27-delivery-acceleration-observability.md","source":"@site/blog/2022-09-27-delivery-acceleration-observability.md","title":"Delivery Acceleration: Observability","description":"When runing services in production the most important thing is to understand the health of it","date":"2022-09-27T00:00:00.000Z","formattedDate":"September 27, 2022","tags":[{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":2.565,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Delivery Acceleration: Observability","description":"When runing services in production the most important thing is to understand the health of it","authors":"kanekotic","tags":["softwaredevelopment","programming","devops","productivity"],"published":"2022-10-05T19:40:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/09/27/delivery-acceleration-observability","cover_image":"https://www.kanekotic.com/img/no_alarms.png","series":"Accelerate Continious Integration & Delivery Practices"},"prevItem":{"title":"Delivery Acceleration: Deployment Environments","permalink":"/blog/2022/10/10/delivery-acceleration-environments"},"nextItem":{"title":"Delivery Acceleration: DevOps Mentality & Practices","permalink":"/blog/2022/09/25/delivery-acceleration-devops-attitudes"}},"content":"When we talk about observability, we talk about:\\n\\n> Capability of developers to understand the health and status of their application.\\n\\n![](https://www.kanekotic.com/img/no_alarms.png)\\n\\nWe don\'t want users or clients to be the ones noticing something is wrong. For this, there are multiple tools that fall under the observability category.\\n\\n## Tools\\n\\n### Alarms\\n\\nThis is the first line of defense against issues, the intent is to get notified if any potential issue arises.  \\nThe intent of this is to provide a notification if any parameter of our application is out of range (ex. to many 5xx).\\n\\nThis allows us to use our mental bandwidth to focus in creating value and not continuously check if the parameters are in range.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Mean Time To Recovery**\\n\\n### Metrics\\n\\nAs the name says, this is a set of measurements we track from our code, it allows us to understand the health of individual parts of our system.\\n\\nThis metrics are shown in dashboards that allow us to visually understand what is happening.  We can divide metrics dashboards in 2 types:\\n\\n* Status: It will give us a really fast overview of the health of the system.\\n* Details: It will not tell us what is wrong, but will provide more detailed information to dig deeper into a specific area.\\n\\nIt\'s important to not mix this 2 together, as they have different purposes. Like with alarms, it helps focus our mental bandwidth in the correct place.\\n\\n![](https://www.kanekotic.com/img/dashboards.jpeg)\\n\\nAs you see in the previous image, the left represents a detail dashboard that makes it difficult to know on a single view if there is an issue. For this, as in the image on the right,  we have a status dashboard that in a single glance we can spot where to look next.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Mean Time To Recovery**\\n\\n### Logs\\n\\nThis is the lower level you want to go. It should tell you where in the code is your issue, so you can go and fix it.\\n\\nWhen thinking about logging, it is significant not log everything. Due to the added noise that this can bring.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Mean Time To Recovery**\\n\\n## Example\\n\\nlet\'s get practical on how would this work.\\n\\n![](https://www.kanekotic.com/img/observability-drawio.png)\\n\\n* Implement your service\\n* Create metrics and send them to your metrics system (ex. [Datadog](https://www.datadoghq.com/), [Grafana](https://grafana.com/))\\n* Create logs and send them to your logging system (ex. [Datadog](https://www.datadoghq.com/), [Kibana](https://www.elastic.co/kibana/), [CloudWatch](https://aws.amazon.com/cloudwatch/)).\\n* Create dashboards:\\n  * Single Status dashboard. Use only simple boxes with green and red backgrounds that represent in one view the health of your system & subsystems.\\n  * Multiple Detail dashboards. Create a dashboard for each subsystem with as much data as necessary to understand where the issue is, so you can later pinpoint the root cause in your logs.\\n* Create alarms based on the status dashboard boxes.\\n* Connect your notification system (ex. [Opsgenie](https://www.atlassian.com/software/opsgenie), [PagerDuty](https://www.pagerduty.com/), [Slack ](https://slack.com/)channel) to the created alarms, so you get push notifications as something goes wrong."},{"id":"/2022/09/25/delivery-acceleration-devops-attitudes","metadata":{"permalink":"/blog/2022/09/25/delivery-acceleration-devops-attitudes","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-25-delivery-acceleration-devops-attitudes.md","source":"@site/blog/2022-09-25-delivery-acceleration-devops-attitudes.md","title":"Delivery Acceleration: DevOps Mentality & Practices","description":"When we run services in production, mentality can make or break our intent to move towards real CI/CD","date":"2022-09-25T00:00:00.000Z","formattedDate":"September 25, 2022","tags":[{"label":"productivity","permalink":"/blog/tags/productivity"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"programming","permalink":"/blog/tags/programming"}],"readingTime":4,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Delivery Acceleration: DevOps Mentality & Practices","description":"When we run services in production, mentality can make or break our intent to move towards real CI/CD","authors":"kanekotic","tags":["productivity","devops","softwaredevelopment","programming"],"published":"2022-09-29T20:00:00.000Z","series":"Accelerate Continious Integration & Delivery Practices","canonical_url":"https://www.kanekotic.com/blog/2022/09/25/delivery-acceleration-devops-attitudes","cover_image":"https://www.kanekotic.com/img/run_it.jpg"},"prevItem":{"title":"Delivery Acceleration: Observability","permalink":"/blog/2022/09/27/delivery-acceleration-observability"},"nextItem":{"title":"Delivery Acceleration: Intro","permalink":"/blog/2022/09/24/devilery-acceleration-intro"}},"content":"When we start our journey towards continuous integration & delivery, the first thing to take in count is the mentality. There are a few of them that will make or break our intent. Let\'s see the most important and also some practices.\\n\\n## Mentality\\n\\n### You build it, you run it\\n\\n![](https://www.kanekotic.com/img/run_it.jpg)\\n\\n> create a DevOps culture, not a Devs vs Ops\\n\\nThis mentality is the idea that the same people who develop the software re in charge to maintain it in good health by observing it.\\n\\nFor many years, this was not the case. Operations & development were handled by different teams. This caused a dystopian situation where each group had a different goal:\\n\\n* **Devs**: deliver as fast as possible. By pushing code to production without observing the side effects of it.\\n* **Ops**: keep system stability.\\n\\nWith the \'you build it, you run it\' mentality, devs focus on their service or work, while Ops becomes a product team that focus on providing the correct tooling for Developers.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u2714\ufe0f **Change Failure Rate**\\n\\n### Embrace Ownership in Failure Culture\\n\\n![](https://www.kanekotic.com/img/1_w7sfzhdxzldtdwt7wfiabg.png)\\n\\n> the problem is not breaking things, is the inability to recover from it\\n\\nNormally, developers feel they need a safety net to feel comfortable to introduce changes to production, this tends to translate in delegating the ownership to others trough peer review or other validation step.  \\nThis lack of ownership have massive effects on the capacity to recover and the gates that code needs to go through, affecting the feedback cycle.\\n\\nTo improve this failure culture is necessary to promote this behavior, having no blame reduces the amount of stress people go through. \\n\\n> If something fails is not an issue of the individual but of the process itself.\\n\\nImagine that every commit goes to production, changes will be so small that fixing or rolling back can be done in minutes or seconds. At the same time, developers will be able to create the correct tooling to feel more comfortable with this practice.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u2714\ufe0f **Change Failure Rate**\\n\\n### Be a Boy Scout\\n\\n![](https://www.kanekotic.com/img/scout.jpeg)\\n\\n> Don\u2019t continue the same path if you think something can be done better\\n\\nAs individuals, need to bring change to our products. If we see any new practice, tool, services\u2026 that can support the work of the team, bring it forward. Don\'t shy away because the team is currently doing it.\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u2714\ufe0f **Change Failure Rate**\\n\\n### Learn & Adapt\\n\\n![](https://www.kanekotic.com/img/learn-64058_960_720-3730821950.jpeg)\\n\\nNot everything is solved in the same way, don\'t follow:\\n\\n> If your only tool is a hammer then every problem looks like a nail\\n\\nFor this, learn and take your time for it. When you have a new problem, as it\'s possible, you don\'t have the correct tool in your toolbox. \\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u2714\ufe0f **Change Failure Rate**\\n\\n## Practices\\n\\n### Firefighter Role\\n\\n![](https://www.kanekotic.com/img/firefighter.jpeg)\\n\\nThe firefighter role is a rotating role inside the team. They are responsible for being the first responder to incidents and helping solve them.  \\nAt the same time, to make sure this person does not suffer from cognitive load due to context switching, this person is not involved on the normal pair rotation and development tasks.  \\nIn exchange, they focus during the week in improving the specific tooling of the project (ex. DB migration tooling).\\n\\nThis affect the next DORA 4 metrics:\\n\\n* \u2714\ufe0f **Deployment frequency**\\n* \u2714\ufe0f **Lead Time for change**\\n* \u2714\ufe0f **Mean Time To Recovery**\\n* \u2714\ufe0f **Change Failure Rate**\\n\\n### On Call Rotation\\n\\n![](https://www.kanekotic.com/img/on-call.jpeg)\\n\\nAs the development team is also in charge of running the service, some of them will require after working hour support. On call is just this, the disposition of team members to take care of their services around the clock.  \\nThis tends to sound bad, but there are ways to not make this suck. I can\'t express it better than [Chris Ford](https://twitter.com/ctford) has already done in this [page](https://ctford.github.io/oncall-charter/).\\n\\nThis affect the next DORA 4 metric:\\n\\n* \u2714\ufe0f **Mean Time To Recovery**\\n\\n## Conclusion\\n\\nThese are the starting point to feel comfortable running things in production without the concern that any issue is a catastrophic thing. Failing is not an issue, the important part is to be able to recover as soon as possible from any problem that arises."},{"id":"/2022/09/24/devilery-acceleration-intro","metadata":{"permalink":"/blog/2022/09/24/devilery-acceleration-intro","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-24-devilery-acceleration-intro.md","source":"@site/blog/2022-09-24-devilery-acceleration-intro.md","title":"Delivery Acceleration: Intro","description":"Why do teams perform differently and what are the tools & practices some team use to differentiate themselves","date":"2022-09-24T00:00:00.000Z","formattedDate":"September 24, 2022","tags":[{"label":"programming","permalink":"/blog/tags/programming"},{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"devops","permalink":"/blog/tags/devops"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":2.635,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Delivery Acceleration: Intro","description":"Why do teams perform differently and what are the tools & practices some team use to differentiate themselves","authors":"kanekotic","tags":["programming","softwaredevelopment","devops","productivity"],"published":"2022-09-24T12:35:55.000Z","series":"Accelerate Continious Integration & Delivery Practices","canonical_url":"https://www.kanekotic.com/blog/2022/09/24/devilery-acceleration-intro","cover_image":"https://www.kanekotic.com/img/key_metrics.png"},"prevItem":{"title":"Delivery Acceleration: DevOps Mentality & Practices","permalink":"/blog/2022/09/25/delivery-acceleration-devops-attitudes"},"nextItem":{"title":"The future of teams: Crossfuctional & T-Shaped","permalink":"/blog/2022/09/13/the-future-of-teams-crossfunctional-and-t-shaped"}},"content":"This is a series I am really looking forward to writing. I have been doing this presentation for the last 3 years in multiple places.\\n\\n## Am I Crazy?\\n\\nThe answer is no, most of the thing you will see on this series comes from practices derived from Extreme Programming, that show how to build quality and value into products. So bear with me for some time.\\n\\n## Motivation\\n\\nA few years ago, I read the book Accelerate that is derived of the analysis of the state of DevOps report that happens in a regular basis.\\n\\n![](https://www.kanekotic.com/img/accelerate.jpg)\\n\\nThe book does not speak only about technology but also speaks about communication, organization, etc. And how this affects effectiveness in teams & companies. I recommend reading the entire book.\\n\\n### 4 key metrics\\n\\nNevertheless, most of the people resume this book (erroneously) in the next table.\\n\\n![](https://www.kanekotic.com/img/key_metrics.png)\\n\\nIt does a comparison on a what are called the 4 key metrics, and provide a classification of performance (teams & companies, since 2017 this classification has evolved).\\n\\nWhat does these 4 key metrics  mean:\\n\\n* **Deployment frequency**: is how often does the team deploy to **production**.\\n* **Lead Time for change**: is how much time does a story take to get to **production**.\\n* **Mean Time To Recovery**: is how fast can we solve a production issues.\\n* **Change Failure Rate**: is how frequently do we break things in production.\\n\\nAll this metrics is helping teams understand their feedback cycle and stability. In the case of the team, I currently work with:\\n\\n* **Deployment Frequency**: once per commit to trunk (while doing trunk-based development) what ends up translating to a few times per day.\\n* **Lead Time for change:** below 1h. We can activate a feature as soon as the code is deployed by the CI/CD using feature flags.\\n* **Mean Time To Recovery**: In minutes. We can activate and deactivate feature flags on the fly if any of the code breaks, and we have a good observability and alarming, so we are the first one to notice.\\n* **Change Failure Rate**: We don\'t optimize for this, as MTTR is more important for us (I will explain why later). Nevertheless, we currently only had 2 minor production issues in the last year, so we are way below 1%. Our CI/CD validations help a lot on this.\\n\\nThe intent of this series is to share the Extreme programming practices that we use to achieve being on the [elite classification of DORA 4](https://www.devops-research.com/quickcheck.html).\\n\\n## Note of Caution\\n\\nAs this twitter thread shows, this is not one size fits all, the challenges of a team are not the challenges of another one.  There is no silver bullet or common root cause to the issue, and each team should use this metrics to track improvements in an unbiased way. For this, the 4 key metrics do not mean anything at company level and should not be used to compare teams.\\n\\n![](https://www.kanekotic.com/img/metrics_caution.png)\\n\\n## Next\\n\\nIn the following installments, I will walk backwards from having something in production and how to keep it running in a healthy manner stress-free up to coding techniques that enable Trunk-based development."},{"id":"/2022/09/13/the-future-of-teams-crossfunctional-and-t-shaped","metadata":{"permalink":"/blog/2022/09/13/the-future-of-teams-crossfunctional-and-t-shaped","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-13-the-future-of-teams-crossfunctional-and-t-shaped.md","source":"@site/blog/2022-09-13-the-future-of-teams-crossfunctional-and-t-shaped.md","title":"The future of teams: Crossfuctional & T-Shaped","description":"Team structure matters, how can we enable teams to be more productive & independent","date":"2022-09-13T00:00:00.000Z","formattedDate":"September 13, 2022","tags":[{"label":"softwaredevelopment","permalink":"/blog/tags/softwaredevelopment"},{"label":"architecture","permalink":"/blog/tags/architecture"},{"label":"technology","permalink":"/blog/tags/technology"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":3.295,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"The future of teams: Crossfuctional & T-Shaped","description":"Team structure matters, how can we enable teams to be more productive & independent","authors":"kanekotic","tags":["softwaredevelopment","architecture","technology","productivity"],"published":"2022-09-13T08:07:58.000Z","series":"","canonical_url":"https://www.kanekotic.com/blog/2022/09/13/the-future-of-teams-crossfunctional-and-t-shaped","cover_image":"https://www.kanekotic.com/img/t-shapped-cross-functional-tshapped-crossfunctional-drawio.png"},"prevItem":{"title":"Delivery Acceleration: Intro","permalink":"/blog/2022/09/24/devilery-acceleration-intro"},"nextItem":{"title":"Event Storming to split Monolith into Microservices","permalink":"/blog/2022/09/09/event-storming-to-split-the-monolith-into-microservices"}},"content":"In software development, over the last years we always talk about on cross-functional teams, as a good split of responsibilities to provide autonomy in teams. What does that mean? Why is this so? And what does it look like?\\n\\n## History & types of teams\\n\\nIt\'s probably easier to see the evolution of team culture as a chronology, as it has been an evolving thing.\\n\\n### Specialization-Based Teams\\n\\nTraditionally, when we had only big monolithic applications, teams have been split by their expertise. This meaning all the quality assurance, Frontend, Backend roles will be in a team with their expertise-based peers. This might look like the next image:\\n\\n![](https://www.kanekotic.com/img/t-shapped-cross-functional-drawio-1.png)\\n\\nWhat are the pros and cons of this model:\\n\\n* \u2714\ufe0f Improve depth of knowledge from peers.\\n* \u2714\ufe0f No dependency on individuals, the Bus factor tends to be bigger than 1.\\n* \u274c Bottlenecks in between teams, due to different priorities and timelines.\\n* \u274c Lack of breath of knowledge.\\n* \u274c Low domain expertise due to coverage of all domains.\\n* \u274c Continuous context switch due to support of multiple domains.\\n* \u274c Design issues due [Conway\'s Law](https://en.wikipedia.org/wiki/Conway%27s_law) relation in between communication patterns and architecture.\\n* \u274c Eventually, teams grow too big and have management issues due to [Dunbar\'s Number](https://en.wikipedia.org/wiki/Dunbar%27s_number \\"dunbars\\") on human relationships.\\n\\n### Specialized Cross-functional Teams\\n\\nDue to the shortcomings of the previous model and the raise of microservices and some concepts from DDD,  the intention of splitting teams was to make sure a specific domain and their solutions were cover by the same people.  \\nThis allows more independence and control over what is required to fulfill the needs of that domain. \\n\\nThis might look like the next image:\\n\\n![](https://www.kanekotic.com/img/t-shapped-cross-functional-expertise-crossfunctional-teams-drawio.png)\\n\\nWhat are the pros and cons of this model:\\n\\n* \u2714\ufe0f Common domain expertise, allowing faster and informed decisions.\\n* \u2714\ufe0f Single domain will not require a lot of context switch.\\n* \u2714\ufe0f Helps design on microservices environments due to [Conway\'s Law](https://en.wikipedia.org/wiki/Conway%27s_law).\\n* \u2714\ufe0f Teams tend to stay small and follow [Dunbar\'s Number](https://en.wikipedia.org/wiki/Dunbar%27s_number \\"dunbars\\") on human relationships (ex. Amazon 2 large pizza team size).\\n* \u274c Bottlenecks in between team members, due to process dependency.\\n* \u274c Lack of depth of knowledge from peers.\\n* \u274c Lack of breath of knowledge being shared.\\n* \u274c Bus factor tends to be small.\\n\\n### T-shaped Cross-Functional Teams\\n\\nThe previous organization helped many teams to be able to focus and do the right thing in the right moment.\\n\\nNevertheless, it lacked the focus on collaboration and support inside the team, as each person has their small set of responsibilities can easily cause bottlenecks inside a single team.\\n\\nT-shaped development tries to solve this by making sure all team members can work in every part of the solution (represented by the horizontal part of the \'T\'). Nevertheless, each member can have his own preferred field of expertise  (represented by the vertical part of the \'T\').   \\nThis has been enabled by the lower complexity on the tooling and entry-level learning curve to most of the expertises.\\n\\n![](https://www.kanekotic.com/img/t-shapped-cross-functional-tshapped-crossfunctional-drawio.png)\\n\\nWhat are the pros and cons of this model:\\n\\n* \u2714\ufe0f No bottlenecks as all team members can chip in to the different needs.\\n* \u2714\ufe0f Common domain expertise, allowing faster and informed decisions.\\n* \u2714\ufe0f Single domain will not require a lot of context switch.\\n* \u2714\ufe0f Helps design on microservices environments due to [Conway\'s Law](https://en.wikipedia.org/wiki/Conway%27s_law).\\n* \u2714\ufe0f Teams tend to stay small and follow [Dunbar\'s Number](https://en.wikipedia.org/wiki/Dunbar%27s_number \\"dunbars\\") on human relationships (ex. Amazon 2 large pizza team size).\\n* \u2714\ufe0f Shared tasks improve a team member depth of knowledge.\\n* \u2714\ufe0f Shared tasks improve  a team member breath of knowledge.\\n* \u2714\ufe0f As knowledge is spread inside the team, the Bus Factor is not an issue.\\n\\n## Conclusion\\n\\nTime has improved things for all teams, and we are probably not at the end of the transformation of teams. Nevertheless, it is good for companies and individuals to adapt to changes in the environment."},{"id":"/2022/09/09/event-storming-to-split-the-monolith-into-microservices","metadata":{"permalink":"/blog/2022/09/09/event-storming-to-split-the-monolith-into-microservices","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-09-event-storming-to-split-the-monolith-into-microservices.md","source":"@site/blog/2022-09-09-event-storming-to-split-the-monolith-into-microservices.md","title":"Event Storming to split Monolith into Microservices","description":"how can we define what is the scope of a service, event storming is here to help us","date":"2022-09-09T00:00:00.000Z","formattedDate":"September 9, 2022","tags":[{"label":"api","permalink":"/blog/tags/api"},{"label":"microservices","permalink":"/blog/tags/microservices"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":4.83,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Event Storming to split Monolith into Microservices","description":"how can we define what is the scope of a service, event storming is here to help us","authors":"kanekotic","tags":["api","microservices","programming","architecture"],"published":"2022-09-12T07:28:48.000Z","series":"The journey from the monolith to microservices","canonical_url":"https://www.kanekotic.com/blog/2022/09/09/event-storming-to-split-the-monolith-into-microservices","cover_image":"https://www.kanekotic.com/img/event-storming.png"},"prevItem":{"title":"The future of teams: Crossfuctional & T-Shaped","permalink":"/blog/2022/09/13/the-future-of-teams-crossfunctional-and-t-shaped"},"nextItem":{"title":"Patterns to avoiding microlithic microservices","permalink":"/blog/2022/09/05/patterns-to-avoiding-microlithic-microservices"}},"content":"On our previous installments, we discussed the smells that can happen when splitting microservices, and the strategies that exist to make them as independent as possible. But how do we define boundaries? How do we define the process that our microservice is in charge off?\\n\\n## Event Storming\\n\\nEvent storming is a technique that is part of [DDD](https://en.wikipedia.org/wiki/Domain-driven_design). But, what is Event storming?, the definition on [Wikipedia](https://en.wikipedia.org/wiki/Event_storming \\"wikipedia\\") is:\\n\\n> A workshop-based method to quickly find out what is happening in the domain of a software program. The business process is \\"stormed out\\" as a series of domain events.\\n\\nThis process is run with stickies in a physical or digital board during a session, and requires the \'experts\' on the process to be present to provide the context what/whom/how. The outcome is an understanding of the **business process**, not the technical one. To be able to separate them into different steps with clear responsibilities.\\n\\n### Step-By-Step Guide\\n\\nlet\'s do an example of how a company sets up our internet connection\\n\\n#### Prepare a board and the people for the session\\n\\nEvent storming requires people to share a common view and brainstorm and discuss on it. This process takes to count time as a dimension. And has multiple types of stickies that can be used.  \\nYou can see an example board on the next image:\\n\\n![](https://www.kanekotic.com/img/event-storming.png)\\n\\nRegarding the Stickies, their color represent a specific meaning\\\\[1\\\\]:\\n\\n* **Events (orange):** Represent the factual events and anything that is relevant to a domain expert.\\n* **Commands (blue):** These are requests to do something. They can originate from a user or system or by another event.\\n* **System (pink):** These represent systems involved in the domain. They may issue commands or receive commands along with triggering events.\\n* **User (yellow):** These are human users involved in the process. They may be a single person or a department/team.\\n* **Aggregate (tan):** This is the first level of categorization and can be thought of as the \u201cthing\u201d that a group of events operates on.\\n* **Read Model (green):** This represents data that may be critical for a user or system to decide.\\n* **Policy (gray):** These represent standards or rules that may need to be executed, such as rules for a compliance policy.\\n\\n#### Define the **Events** of your system\\n\\nEvents are the most important information of our board. They represent facts regarding the process and helps encapsulate the knowledge of the \'experts\'.  \\nAs we mention before, time is a significant dimension. A process always happens in a period of time. Starting by organizing this \'things\' that happen in a timeline is a good way to start.  \\n![](https://www.kanekotic.com/img/event-storming-map-events-drawio.png)\\n\\nIn our example, you can see on the previous image we go from checking coverage, to creating a user, to creating a contract and connecting our user to the network.\\n\\n#### Identify the **Systems** involved (Optional)\\n\\nThe intent of this step is to identify the existing systems and their interdependency. When we discuss systems, they can be internal or external.\\n\\n![](https://www.kanekotic.com/img/event-storming-map-systems-drawio.png)\\n\\nIn our example, all starts with the website, but soon enough it becomes apparent most of the process is taken care by the monolith.\\n\\nThis step is optional in the case you have a greenfield. Nevertheless, I highly recommend it if you are splitting a monolith.\\n\\n#### Add the **Actors**\\n\\nThese are real people who are part of the process, they tend to be the starting point of a chain of events, or even on a manual process we are trying to automate the executors of the individual step.\\n\\n![](https://www.kanekotic.com/img/event-storming-map-actors-drawio.png)  \\nIn our case, the user is the one starting the process, but there needs to be a technician doing the last steps manually.\\n\\n#### Connect the dots with **Commands**\\n\\nNow we are left with events that are done by someone and take effect in parts of our system. But we are missing the cause and effect that made this look this way.\\n\\nCommands allow exactly this, is a specific action or decision that will push our system into a certain direction.\\n\\n![](https://www.kanekotic.com/img/event-storming-map-commands-drawio.png)\\n\\nCommands can be positive or negative actions, causing bifurcation and showing different cases that our system needs to cope with.\\n\\n#### Define **Bounded Context**\\n\\nnow we are left to define where each of the sub-process that conform our system starts and ends. This is done by grouping the stickies with an enclosing and giving a noun + verb to it, as it\'s a sub-process and it evokes action.  \\n![](https://www.kanekotic.com/img/event-storming-bounded-contexts-drawio.png)\\n\\nNow you have a set of split actions that can become their microservices and provide part of the process independently.\\n\\n#### Create **Capabilities Matrix** (Optional)\\n\\nNow, with the bounded context, we can start defining the capabilities of our services. This is straightforward to express in a matrix.\\n\\n| Context | Capabilities |\\n| --- | --- |\\n| Network Management | Check coverage <br/> Enable Network <br/> 3rd party Hardware management integration |\\n| User Management | Create User <br/> User Email Verification |\\n| contract Management | Create Contract <br/> User Email Verification <br/> 3rd party digital signature integration |\\n\\n#### Devise your **Goal Architecture** (Optional)\\n\\nKnowing our current architecture, it\'s good to think where we want to go.   \\nThis is not only a technical challenge, but an organizational challenge due to [Conway\'s law](https://en.wikipedia.org/wiki/Conway%27s_law). If we would like to be successful in splitting a monolith our communication, meaning the teams structure involved, need to resemble this target state.\\n\\n![](https://www.kanekotic.com/img/event-storming-goal-architecture-drawio.png)\\n\\n#### Define a **plan** on how to split the Monolith (Optional)\\n\\nA change so big as the one shown on the previous image can be overwhelming for an organization and create a paralysis and doubts. It\'s always good to split the problem in steps to understand progress and be always on a better state. This will improve morale.  \\n![](https://www.kanekotic.com/img/event-storming-plan-architecture-drawio.png)\\n\\n###### \\\\[1\\\\] [https://www.capitalone.com/tech/software-engineering/event-storming-for-microservice-architecture/](https://www.capitalone.com/tech/software-engineering/event-storming-for-microservice-architecture/ \\"https://www.capitalone.com/tech/software-engineering/event-storming-for-microservice-architecture/\\")"},{"id":"/2022/09/05/patterns-to-avoiding-microlithic-microservices","metadata":{"permalink":"/blog/2022/09/05/patterns-to-avoiding-microlithic-microservices","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-05-patterns-to-avoiding-microlithic-microservices.md","source":"@site/blog/2022-09-05-patterns-to-avoiding-microlithic-microservices.md","title":"Patterns to avoiding microlithic microservices","description":"how can we decouple services to avoid some common pitfalls","date":"2022-09-05T00:00:00.000Z","formattedDate":"September 5, 2022","tags":[{"label":"api","permalink":"/blog/tags/api"},{"label":"microservices","permalink":"/blog/tags/microservices"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":2.24,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Patterns to avoiding microlithic microservices","description":"how can we decouple services to avoid some common pitfalls","authors":"kanekotic","tags":["api","microservices","programming","architecture"],"published":"2022-09-05T06:22:55.000Z","series":"The journey from the monolith to microservices","canonical_url":"https://www.kanekotic.com/blog/2022/09/05/patterns-to-avoiding-microlithic-microservices","cover_image":"https://www.kanekotic.com/img/microliths.jpg"},"prevItem":{"title":"Event Storming to split Monolith into Microservices","permalink":"/blog/2022/09/09/event-storming-to-split-the-monolith-into-microservices"},"nextItem":{"title":"Common mistakes when splitting the monolith","permalink":"/blog/2022/09/04/common-mistakes-when-splitting-the-monolith"}},"content":"On the previous installment of this series, we discussed the pitfalls that could happen when we split a monolith into microservices. In specific, we talked about creating what are called microliths.  \\n![](https://www.kanekotic.com/img/microliths.jpg)\\n\\nGiven that you have followed the recommendations on designing your domains correctly. Today we are going to elaborate on patterns to remove that synchronous communication in between \'microservices\'. This will help our services to become more resilient.\\n\\n## The Patterns\\n\\n### Circuit Breakers\\n\\nThe most simple solution we can go for is called **circuit breakers**. As it implies, is just a piece of code that upon multiple request failed to a downstream service will fail silently and allow service to resume their normal behavior.\\n\\n![](https://www.kanekotic.com/img/circuitbreakerdesignpattern.png)\\n\\nWhat are we solving and what are we letting unsolved:\\n\\n* \u2714\ufe0f We don\u2019t fail continuously if some other service fails.\\n* \u274c We silently don\u2019t finish the entire process requested.\\n* \u274c We require all chain of dependencies to be called.\\n* \u274c We force other services to scale to our needs.\\n* \u274c Data is mutable, so errors will be propagated and not solvable.\\n\\n### Outbox Pattern\\n\\nThe next level in solving our microlithic issue is to decouple our services using Pub/Sub to exchange models in between services.  \\nOur service will consume and store the necessary information to run the process locally, and will broadcast the outcome models. This will mean there will always be a strong consistency in the outbox, and eventual consistency on the service database (if it exists).\\n\\n![](https://www.kanekotic.com/img/reactivemicroliths.jpg)\\n\\nWhat are we solving and what are we letting unsolved:\\n\\n* \u2714\ufe0f We don\u2019t fail continuously if some other service fails.\\n* \u2714\ufe0f We always finish our process and promise the rest will be done.\\n* \u2714\ufe0f We just require our service to do what we promise.\\n* \u2714\ufe0f Fast services will be fast, and slow services can go slow.\\n* \u274c Data is mutable, so errors will be propagated and not solvable.\\n\\n### Event Sourcing\\n\\nThe last level is **event sourcing**. The idea is to use the events that generated a specific state and not use the calculated state that a service can provide us.\\n\\nThis allows a higher resilience due to the immutability of the data. In this case, calculation issues of the past can be solved, as we can reprocess the entire set of events that took us to a certain state.  \\n![](https://www.kanekotic.com/img/microsystems.jpg)\\n\\n## Conclusion and follow-ups\\n\\nThese are some of the patterns that can make our services more independent and resilient. Nevertheless, each of them has a different complexity, meaning it also affects the complexity of our code. For this, we need to make sure we use the correct tool for the job."},{"id":"/2022/09/04/common-mistakes-when-splitting-the-monolith","metadata":{"permalink":"/blog/2022/09/04/common-mistakes-when-splitting-the-monolith","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-09-04-common-mistakes-when-splitting-the-monolith.md","source":"@site/blog/2022-09-04-common-mistakes-when-splitting-the-monolith.md","title":"Common mistakes when splitting the monolith","description":"A set of the most common mistakes when splitting your monolith into microservices","date":"2022-09-04T00:00:00.000Z","formattedDate":"September 4, 2022","tags":[{"label":"api","permalink":"/blog/tags/api"},{"label":"microservices","permalink":"/blog/tags/microservices"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"architecture","permalink":"/blog/tags/architecture"}],"readingTime":3.63,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"draft":false,"title":"Common mistakes when splitting the monolith","description":"A set of the most common mistakes when splitting your monolith into microservices","authors":"kanekotic","tags":["api","microservices","programming","architecture"],"published":"2022-09-04T10:32:34.000Z","series":"The journey from the monolith to microservices","canonical_url":"https://www.kanekotic.com/blog/2022/09/04/common-mistakes-when-splitting-the-monolith","cover_image":"https://user-images.githubusercontent.com/3071208/188307797-7c30c8cb-bff7-4755-822b-7cf469cba372.JPG"},"prevItem":{"title":"Patterns to avoiding microlithic microservices","permalink":"/blog/2022/09/05/patterns-to-avoiding-microlithic-microservices"},"nextItem":{"title":"Automate Anything: Power Automate + Trello + IFTTT","permalink":"/blog/2022/08/24/power-automate-automating-social-media"}},"content":"## The Monolith\\n\\nWe have all at this point encounter the big service that jumpstarted the business. It\'s always good to find it or know it existed. It shows that there was an intent to not resolve every architectural problem before we even knew we had a business.\\n\\nNevertheless, it tends to outgrow itself and become more a pain than a solution. Some of these pains are:\\n\\n* We all work on the same code base, and conflicts and side effects start to happen.\\n* You need to release the entire solution, even if different teams have different cycles.\\n* There are code freezes to go through validation cycles.\\n* It scales as a whole, not only the portion that has an increase in traffic.\\n\\nDue to these pains, microservices were created. To give team/domain independence to create focused solutions on a business that has already been validated.\\n\\n![](https://www.kanekotic.com/img/monolith.JPG)\\n\\n## The Microservices\\n\\nLet\'s start with a [definition of a microservice](https://aws.amazon.com/microservices/):\\n\\n> Microservices are an architectural and organizational approach to software development where software is composed of small independent services that communicate over well-defined APIs. These services are owned by small, self-contained teams.\\n\\n![microservices](https://user-images.githubusercontent.com/3071208/188307797-7c30c8cb-bff7-4755-822b-7cf469cba372.JPG)\\n\\nAll sounds like flowers and happiness when we talk about microservice. Nevertheless, does microservices solve the entire issue by itself?\\n\\nHave you encountered the next cases in a microservice architecture?\\n\\n* Before we release a new version, we need to sync deploys with another team.\\n* Our application was down, but is not our issue.\\n* Our service was working and scaling fine until the team X started using us.\\n* And more\u2026\\n\\nWhat is happening?\\n\\n### Microliths\\n\\nThe smells mention before are caused by what [Jonas Boner](http://jonasboner.com/) call Microliths, a great word for what is happening here.  \\nEven if we think this are \'independent\' services, synchronous communication can cause side effects we don\'t want:\\n\\n* There can be cascading events between your services.\\n* Your domain boundaries are not clear because you don\u2019t own the entire process.\\n* Slow services are forced to scale by faster services requirements.\\n* There is additional latency on the network calls.\\n\\n![](https://microlithalternatives.kanekotic.com/images/microliths.jpg)\\n\\n### What got lost in translation?\\n\\nHaving microliths comes from multiple misconceptions we have. Some of them are:\\n\\n#### Domains != Resources\\n\\nEvery so often, when we divide the monolith, we think about domains being resources. Due to how we normally have divided API\'s and DB\'s as we think about splitting what already exists and not about extracting the processes being achieved.\\n\\nWhen thinking about a microservice, we should think about what part of the process it is trying to solve, this will help us define good boundaries for our bounded context.\\n\\nWhen we think in a process, data is secondary. The process will require different pieces of existing data to fulfill their capabilities, and it is ok for it to own its copy of what is needed to fulfill his mission.\\n\\n#### Independence != Single Source\\n\\nA single source of data does not mean independence, as whenever your software requires complementary data, it will have to acquire it from somewhere else, what means a direct  dependency. This also affects boundaries as you must enter other team\'s domain.\\n\\nIf you strive for independence, copy the information you require for your process, even if it exists somewhere else.\\n\\n#### Fast != Synchronous\\n\\nHumans think that a direct response is always faster than sending out a message. While occasionally this is true, in microservices this could start a cascade of synchronous calls from one service to the next one, leaving our users in a timeout limbo.\\n\\nThink if really your system requires calling others directly or if you can message them to start their process.\\n\\n#### Resilience != Complete\\n\\nMaking sure the entire process has been completed, is normally confused by resiliency. Resiliency only refers to the capability to complete the process.  \\nIf we have well-defined contracts in between our pieces, we don\'t need to finish things synchronously, we can promise our users things will happen. And let our services do their work at their speed.\\n\\n## Conclusion and follow-ups\\n\\nAre we doomed?  \\n![](https://microlithalternatives.kanekotic.com/images/timetopanic.jpg)\\n\\nThe answer is no, we are not doomed! We can design our services with the correct division using some DDD tooling and also use the correct tools to decouple our microservices.  \\nLet\'s talk about this on the next chapters of this series."},{"id":"/2022/08/24/power-automate-automating-social-media","metadata":{"permalink":"/blog/2022/08/24/power-automate-automating-social-media","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-08-24-power-automate-automating-social-media.md","source":"@site/blog/2022-08-24-power-automate-automating-social-media.md","title":"Automate Anything: Power Automate + Trello + IFTTT","description":"how to automate tedius tasks with low code platforms","date":"2022-08-24T00:00:00.000Z","formattedDate":"August 24, 2022","tags":[{"label":"lowcode","permalink":"/blog/tags/lowcode"},{"label":"serverless","permalink":"/blog/tags/serverless"},{"label":"showdev","permalink":"/blog/tags/showdev"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":0.905,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Automate Anything: Power Automate + Trello + IFTTT","description":"how to automate tedius tasks with low code platforms","authors":"kanekotic","tags":["lowcode","serverless","showdev","productivity"],"draft":false,"published":"2022-08-23T22:00:00.000Z","series":"","canonical_url":"https://www.kanekotic.com/blog/2022/08/24/power-automate-automating-social-media","cover_image":"https://github.com/kanekotic/diagrams/blob/main/automate.drawio.png?raw=true"},"prevItem":{"title":"Common mistakes when splitting the monolith","permalink":"/blog/2022/09/04/common-mistakes-when-splitting-the-monolith"},"nextItem":{"title":"Commiting Like a Pro in NodeJs: The Message","permalink":"/blog/2022/08/09/commiting-like-pro-part-2"}},"content":"## Video\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/KhrRVrCmtIw\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\" allowfullscreen></iframe>\\n\\n## Long Version\\n\\nI am currently starting some new open-source projects and I feel it is tedious to do some recurrent tasks. For example:\\n\\n* Promote this blog post in social media\\n* Announce a new release.\\n\\n[Power Automate](https://powerautomate.microsoft.com/en-us/) & [IFTTT](https://ifttt.com/) integrations allow just this, by a process of action and reaction.  \\n![](https://github.com/kanekotic/diagrams/blob/main/automate.drawio.png?raw=true)\\n\\nThese systems provide:\\n\\n* **Triggers**: they are the starting point of what will happen after.\\n* **Actions**: they react to previous steps on the described flow.\\n\\nAn example of this is the next flow:\\n\\n![image](https://user-images.githubusercontent.com/3071208/186482177-7b6eb6c0-8632-4cd2-87c9-613788f553f8.png)\\n\\n![image](https://user-images.githubusercontent.com/3071208/186478753-1ebcf35c-eb1e-492a-b41c-ac67a749d7f5.png)\\n\\n* In IFTTT, if a new feed item exists in the RSS of my blog, it\'s posted as a card in a Trello board.\\n* The Power automate flow looks for new cards on that column.\\n* Retrieve the content\\n* post it into medium\\n* Post into Twitter and LinkedIn about the new blog post.\\n\\nAs you can see, automation is cool and can save us a lot of effort by increasing our productivity."},{"id":"/2022/08/09/commiting-like-pro-part-2","metadata":{"permalink":"/blog/2022/08/09/commiting-like-pro-part-2","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-08-09-commiting-like-pro-part-2.md","source":"@site/blog/2022-08-09-commiting-like-pro-part-2.md","title":"Commiting Like a Pro in NodeJs: The Message","description":"Using tools to create descriptive commits","date":"2022-08-09T00:00:00.000Z","formattedDate":"August 9, 2022","tags":[{"label":"webdev","permalink":"/blog/tags/webdev"},{"label":"git","permalink":"/blog/tags/git"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":4.365,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Commiting Like a Pro in NodeJs: The Message","description":"Using tools to create descriptive commits","authors":"kanekotic","tags":["webdev","git","programming","productivity"],"draft":false,"published":"2022-08-08T22:00:00.000Z","series":"commiting Like a Pro in NodeJs","canonical_url":"https://www.kanekotic.com/blog/2022/08/09/commiting-like-pro-part-2","cover_image":"https://commitizen-tools.github.io/commitizen/images/demo.gif"},"prevItem":{"title":"Automate Anything: Power Automate + Trello + IFTTT","permalink":"/blog/2022/08/24/power-automate-automating-social-media"},"nextItem":{"title":"Commiting Like a Pro in NodeJs: The hooks","permalink":"/blog/2022/08/08/commiting-like-pro-part-1"}},"content":"## Why are messages important?\\n\\nCommit messages are part of the collaboration we do day to day inside a team, it works as a record of what has happened.\\n\\n> Every time you perform a commit, you\u2019re recording a snapshot of your project that you can revert to or compare to later.\\n>\\n> \u2014 Pro Git Book\\n\\nCommit messages are used in many ways, including:\\n\\n* To help a future reader quickly understand what changed and why it changed\\n* To assist with easily undoing specific changes\\n* To prepare change notes or bump versions for a release\\n\\nAll three of these use cases require a clean and consistent commit message style.\\n\\n## Easy Commit messages with Commitizen\\n\\nThis tool purpose is to define a standard way of committing rules and communicating it. The reasoning behind it is that it is easier to read, and enforces writing descriptive commits. Removing the ambiguity of options and the mental load of following the standard manually.\\n\\n[Commitizen](https://github.com/commitizen) will prompt you a series of questions that will generate the final commit message. It has multiple adapters, in my case I prefer to be controlling the questions, so I use [cz-format-extension](https://github.com/tyankatsu0105/cz-format-extension \\"tyankatsu0105/cz-format-extension\\").\\n\\n![](https://commitizen-tools.github.io/commitizen/images/demo.gif)\\n\\nYou can add commitizen to your project with the next command line\\n\\n```sh\\nnpm install commitizen --save-dev # npm\\nyarn add commitizen -D  # Yarn\\n```\\n\\nAdd any of the available [adapters](https://github.com/commitizen/cz-cli#adapters), in my case [cz-format-extension](https://github.com/tyankatsu0105/cz-format-extension \\"tyankatsu0105/cz-format-extension\\"):\\n\\n```sh\\n    npm install cz-format-extension --save-dev # npm\\n    yarn add cz-format-extension -D  # Yarn\\n```\\n\\nIn your `package.json` you will need to add the next section:\\n\\n```sh\\n  ...\\n  \\"config\\": {\\n    ...\\n    \\"commitizen\\": {\\n      \\"path\\": \\"cz-format-extension\\"\\n    }\\n  }\\n  ...\\n```\\n\\nThe Adapter [cz-format-extension](https://github.com/tyankatsu0105/cz-format-extension \\"tyankatsu0105/cz-format-extension\\") allows a massive flexibility as the questions can be defined in a `.czfrec.js` file. An example is:\\n\\n```js\\nconst { contributors } = require(\'./package.json\')\\n\\nmodule.exports = {\\n  questions({inquirer}) {\\n    return [\\n      {\\n        type: \\"list\\",\\n        name: \\"type\\",\\n        message: \\"\'What is the type of this change:\\",\\n        choices: [\\n           {\\n              type: \\"list\\",\\n              name: \\"type\\",\\n              message: \\"\'What is the type of this change:\\",\\n              choices: [\\n          {\\n            \\"name\\": \\"feat: A new feature\\",\\n            \\"value\\": \\"feat\\"\\n          },\\n          {\\n            \\"name\\": \\"fix: A bug fix\\",\\n            \\"value\\": \\"fix\\"\\n          },\\n          {\\n            \\"name\\": \\"docs: Documentation only changes\\",\\n            \\"value\\": \\"docs\\"\\n          },\\n          ...\\n        ]\\n      },\\n      {\\n        type: \'list\',\\n        name: \'scope\',\\n        message: \'What is the scope of this change:\',\\n        choices: [\\n            {\\n              \\"name\\": \\"core: base system of the application\\",\\n              \\"value\\": \\"core\\"\\n            },\\n            {\\n              \\"name\\": \\"extensions: systems that are observed\\",\\n              \\"value\\": \\"extensions\\"\\n            },\\n            {\\n              \\"name\\": \\"tools: other things in the project\\",\\n              \\"value\\": \\"tools\\"\\n            },\\n        ]\\n      },\\n      {\\n        type: \'input\',\\n        name: \'message\',\\n        message: \\"Write a short, imperative tense description of the change\\\\n\\",\\n        validate: (message) => message.length === 0 ? \'message is required\' : true\\n      },\\n      {\\n        type: \'input\',\\n        name: \'body\',\\n        message: \'Provide a longer description of the change: (press enter to skip)\\\\n\',\\n      },\\n      {\\n        type: \'confirm\',\\n        name: \'isBreaking\',\\n        message: \'Are there any breaking changes?\',\\n        default: false\\n      },\\n      {\\n        type: \'input\',\\n        name: \'breaking\',\\n        message: \'Describe the breaking changes:\\\\n\',\\n        when: answers => answers.isBreaking\\n      },\\n      {\\n        type: \'confirm\',\\n        name: \'isIssueAffected\',\\n        message: \'Does this change affect any open issues?\',\\n        default: false\\n      },\\n      {\\n        type: \'input\',\\n        name: \'issues\',\\n        message: \'Add issue references:\\\\n\',\\n        when: answers => answers.isIssueAffected,\\n        default: undefined,\\n        validate: (issues) => issues.length === 0 ? \'issues is required\' : true\\n      },\\n      {\\n        type: \'checkbox\',\\n        name: \'coauthors\',\\n        message: \'Select Co-Authors if any:\',\\n        choices: contributors.map(contributor => ({\\n            name: contributor.name,\\n            value: `Co-authored-by: ${contributor.name} <${contributor.email}>`,\\n        }))\\n      },\\n    ]\\n  },\\n  commitMessage({answers}) {\\n    const scope = answers.scope ? `(${answers.scope})` : \'\';\\n    const head = `${answers.type}${scope}: ${answers.message}`;\\n    const body = answers.body ? answers.body : \'\';\\n    const breaking = answers.breaking ? `BREAKING CHANGE: ${answers.breaking}` : \'\';\\n    const issues = answers.issues ? answers.issues : \'\';\\n    const coauthors = answers.coauthors.join(\'\\\\n\');\\n\\n    return [head, body, breaking, issues, coauthors].join(\'\\\\n\\\\n\').trim()\\n  }\\n}\\n```\\n\\nThe file creates a process of questions for:\\n\\n* type: align with semantic release message specification\\n* scope: affected part of the application\\n* message: the imperative written message\\n* body: longer description\\n* breaking: to determine if it\'s a breaking change for semantic release\\n* Issue: related issue of our ticketing system\\n* Co-Authors: people working in the tasks while pair programming\\n\\nAll these questions are asked interactively and not by the brain power of doing manual work.\\n\\nAnd you can then add some nice npm scripts in your `package.json` file pointing to the local version of Commitizen:\\n\\n      ...\\n      \\"scripts\\": {\\n        \\"commit\\": \\"cz\\"\\n      }\\n\\nThis will be more convenient for your users because then if they want to do a commit, all they need to do is run `npm run commit` and they will get the prompts needed to start a commit!\\n\\n> **NOTE:** If you are using `precommit` hooks thanks to something like [`husky`](https://www.npmjs.com/package/husky), you will need to name your script something other than `\\"commit\\"` (e.g. `\\"cm\\": \\"cz\\"`). The reason is because npm scripts has a \\"feature\\" where it automatically runs scripts with the name _prexxx_ where _xxx_ is the name of another script. In essence, npm and husky will run `\\"precommit\\"` scripts twice if you name the script `\\"commit\\"`, and the workaround is to prevent the npm-triggered _precommit_ script.\\n\\nThat is all :) . I will do a special mention to [commitlint](https://commitlint.js.org/#/) that is a very useful tool to lint commit messages. I do not use it anymore as it has some overlap with commitizen."},{"id":"/2022/08/08/commiting-like-pro-part-1","metadata":{"permalink":"/blog/2022/08/08/commiting-like-pro-part-1","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-08-08-commiting-like-pro-part-1.md","source":"@site/blog/2022-08-08-commiting-like-pro-part-1.md","title":"Commiting Like a Pro in NodeJs: The hooks","description":"Using git hooks to make sure your commits do what you expect","date":"2022-08-08T00:00:00.000Z","formattedDate":"August 8, 2022","tags":[{"label":"agile","permalink":"/blog/tags/agile"},{"label":"webdev","permalink":"/blog/tags/webdev"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":2.13,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Commiting Like a Pro in NodeJs: The hooks","description":"Using git hooks to make sure your commits do what you expect","authors":"kanekotic","tags":["agile","webdev","programming","productivity"],"draft":false,"published":"2022-08-07T22:00:00.000Z","series":"commiting Like a Pro in NodeJs","canonical_url":"https://www.kanekotic.com/blog/2022/08/08/commiting-like-pro-part-1"},"prevItem":{"title":"Commiting Like a Pro in NodeJs: The Message","permalink":"/blog/2022/08/09/commiting-like-pro-part-2"},"nextItem":{"title":"Stop doing PR\'s inside the Office","permalink":"/blog/2022/08/08/stop-prs"}},"content":"## What & Why Git hooks?\\n\\nGit hooks are scripts that Git executes locally before or after events such as commit, push, and receive.\\n\\nThese hooks are completely programmable trough bash scripting. Examples of what can be done:\\n\\n* pre-commit: Enforce project coding standards.\\n* pre-push: Run tests.\\n\\nThis allows us to make sure we are committing the correct things at the correct time. Not breaking our code just because of the mental load of doing things as a manual process that can be forgotten.\\n\\n## How to Start\\n\\n### Add Husky\\n\\n[Husky](https://typicode.github.io/husky/#/) is a tool that allows Git hooks using JavaScript configured using individual files for hooks in a `.husky/` directory.\\n\\nThe fastest way to install husky is by using `husky-init`, a one-time command to quickly initialize a project with husky:\\n\\n```sh\\nnpx husky-init && npm install       # npm\\nnpx husky-init && yarn              # Yarn 1\\nyarn dlx husky-init --yarn2 && yarn # Yarn 2+\\npnpm dlx husky-init && pnpm install # pnpm\\n```\\n\\nIt will set up husky, modify package.json and create a sample pre-commit hook that you can edit. By default, it will run test when you commit.\\n\\nTo add another hook, use `husky add`.\\n\\nIf you are not comfortable using  `husky-init` you can find other options [here](https://typicode.github.io/husky/#/?id=manual).\\n\\n### Add lint-staged\\n\\nHusky is very useful, but it will run natively to git and not focus the commands in our bash scripts for all the files, not only the ones we want to commit.\\n\\n[Lint Staged](https://github.com/okonet/lint-staged) appear to resolve this problem. It allows you to run the process against staged git files that match a pattern.\\n\\n[![asciicast](https://asciinema.org/a/199934.svg)](https://asciinema.org/a/199934)\\n\\nInstall `lint-staged` by adding it to your local project.\\n\\n```sh\\nnpm install lint-staged --save-dev\\nyarn add lint-staged -D \\n```\\n\\nIn your package.json add it as a script(`\\"lint-staged\\": \\"lint-staged\\",`) and refer it through a `pre-commit` hook. If using Husky, this can be found in `.husky/pre-commit` with the next content:\\n\\n```sh\\n#!/bin/sh\\n. \\"$(dirname \\"$0\\")/_/husky.sh\\"\\n\\nyarn lint-staged\\n```\\n\\nThere are multiple ways to [configure lint-staged](https://github.com/okonet/lint-staged#configuration). One of them is having a `lint-staged.config.js` file in your project root folder. In this file, you can express what process you want to run for what types of files. For example:\\n\\n```js\\nmodule.exports = {\\n  \'*.{ts,tsx}\': [() => \'yarn tsc:check\', \'yarn format\', \'yarn lint:fix\', \'yarn test\', \'git add .\'],\\n};\\n```\\n\\nThe previous snipped runs the compiler check, formatting, linting and test before adding the fixed staged files to the current commit.\\n\\n## Conclusion\\n\\nWith this two tools, we will now be pushing code that will pass similar checks than our CI/CD system."},{"id":"/2022/08/08/stop-prs","metadata":{"permalink":"/blog/2022/08/08/stop-prs","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2022-08-08-stop-prs.md","source":"@site/blog/2022-08-08-stop-prs.md","title":"Stop doing PR\'s inside the Office","description":"PRs should only be part of certain environments and not a general practice","date":"2022-08-08T00:00:00.000Z","formattedDate":"August 8, 2022","tags":[{"label":"agile","permalink":"/blog/tags/agile"},{"label":"webdev","permalink":"/blog/tags/webdev"},{"label":"programming","permalink":"/blog/tags/programming"},{"label":"productivity","permalink":"/blog/tags/productivity"}],"readingTime":3.02,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Stop doing PR\'s inside the Office","description":"PRs should only be part of certain environments and not a general practice","authors":"kanekotic","tags":["agile","webdev","programming","productivity"],"draft":false,"published":"2022-08-07T22:00:00.000Z","canonical_url":"https://www.kanekotic.com/blog/2022/08/08/stop-prs","cover_image":"https://github.com/kanekotic/diagrams/blob/main/Stop%20doing%20PR.drawio.png?raw=true"},"prevItem":{"title":"Commiting Like a Pro in NodeJs: The hooks","permalink":"/blog/2022/08/08/commiting-like-pro-part-1"},"nextItem":{"title":"Update your npm package dependencies and release with Travis","permalink":"/blog/2018/07/11/travis-ci-update-npm-package-dependencies-and-release"}},"content":"Over the last few years, some practices appear to be more a dogma than a value adding practice. One of this is `Pull Requests`.\\n\\n### Why PR\'s exist\\n\\n* **Malicious Code Prevention**: Pull requests exist mostly as a practice accepted for `zero trust environments` (ex. Open Source). An attack vector on this type of environment is the ability of anyone to contribute, meaning you could inject code that could create known vulnerabilities that packages will inherit. That is why maintainers validate code from unknown users.\\n\\n![Malicious actors](https://github.com/kanekotic/diagrams/blob/main/Stop%20doing%20PR.drawio.png?raw=true)\\n\\n* **Highly Distributed Teams**: PR\'s can be use for highly distributed teams (around the clock) as a way to do knowledge sharing. If someone in side A of the world can follow and understand the changes for a feature that is being developed in side B of the world.\\n\\n![Distributed Teams](https://github.com/kanekotic/diagrams/blob/main/Stop%20doing%20PR-Around%20The%20Clock.drawio.png?raw=true)\\n\\n### The issue\\n\\nIS there any value of doing PRs when people work collocated? What is the cost of PRs in trust environments?\\n\\nThe value that normally people give to PRs is the one of having a **peer review process**. Nevertheless, we will see later in this article that there are less invasive ways to do this.\\n\\nSome costs of PRs are:\\n\\n* **Slow Delivery**: PRs are a start and stop strategy where there is a gateway to merge code. This is time that needs to be taken by developers (writting & preparing a PR) and reviewers (reviewing, commenting, etc) to go through the process. At the same time is more time the code takes to get to production (merging, re-testing, etc). This is significant for features but also for fixes, meaning you can go from a response time of minutes to hours.\\n* **Isolation work**: When working on branches, devs work on code that works isolated but needs to be merged with a continuous stream of changes. This means that any test isolated will probably be invalidated upon merging.\\n* **Lack of ownership**: As work is done isolated, the developer who creates a PR delegates part or the responsibility to the reviewer. Humans don\'t have compilers or containers to run the code in our brain, meaning catching errors tends to be out of our realm.\\n* **Egos**: As catching errors tends to be out of our human realm, PRs tend to become a thing related to preferences (Style, patterns, etc). This hardly provides any value to the code as either tools like linters can do this automatically or it brings premature optimizations.\\n* **Late feedback**: Any valid recommendation is actually provided quite late in the process, when the code has already been written and validated. Causing rework that takes time.\\n\\n### The Alternatives\\n\\n`Pull requests` are just one of the asynchronous peer code reviews styles. Is not the only way of doing peer reviews.\\n\\nSome other types of peer reviews that I, personally, like are:\\n\\n* **Over-the-shoulder**: The bases of this is to have a conversation over what has been or is being implemented. This creates a synchronous feedback loop on an async process. It does not fix all the shortcomings of a PR, but it creates a faster feedback loop.\\n* **Pair Programming / Mob Programming**: The idea is that multiple developers work in the same code base in the same computer, creating a synchronous feedback loop in a synchronous process. This with `Trunk-based development` allows very fast feedback loops at product level, and with the correct tools generates resilience and ownership among developers.\\n\\nThe disclaimer here is I have worked doing pair programming, TDD and trunk-based development for more than 5 years in multiple size companies, and it has always been a bliss."},{"id":"/2018/07/11/travis-ci-update-npm-package-dependencies-and-release","metadata":{"permalink":"/blog/2018/07/11/travis-ci-update-npm-package-dependencies-and-release","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2018-07-11-travis-ci-update-npm-package-dependencies-and-release.md","source":"@site/blog/2018-07-11-travis-ci-update-npm-package-dependencies-and-release.md","title":"Update your npm package dependencies and release with Travis","description":"Update your npm package dependencies and release with Travis","date":"2018-07-11T00:00:00.000Z","formattedDate":"July 11, 2018","tags":[{"label":"ci","permalink":"/blog/tags/ci"},{"label":"cd","permalink":"/blog/tags/cd"},{"label":"versioning","permalink":"/blog/tags/versioning"},{"label":"npm","permalink":"/blog/tags/npm"},{"label":"travis","permalink":"/blog/tags/travis"},{"label":"travisci","permalink":"/blog/tags/travisci"},{"label":"github","permalink":"/blog/tags/github"},{"label":"cron","permalink":"/blog/tags/cron"}],"readingTime":2.01,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Update your npm package dependencies and release with Travis","description":"Update your npm package dependencies and release with Travis","authors":"kanekotic","tags":["ci","cd","versioning","npm","travis","travisci","github","cron"],"draft":false,"published":"2030-08-01T22:00:00.000Z"},"prevItem":{"title":"Stop doing PR\'s inside the Office","permalink":"/blog/2022/08/08/stop-prs"},"nextItem":{"title":"Create your User/Organization GitHub Page with Hugo + Travis","permalink":"/blog/2018/07/04/deploy-hugo-with-travis"}},"content":"As a member of the community that like to generate npm packages like libraries and cli tools, sometimes is difficult to maintain everything and keep your package up to date in the dependencies side. I am a fan of having static dependencies as versioning is not being held correctly in most of the npm world. So if you dont use exact packages you could run in the issue that a broken change makes from the night to the morning your awesome tool to break.\\n\\nThis practice could bring a headache to keep dependencies up to date because is a manual process. And manual process tend to be time consuming (at this point in time I have ~17 npm packages) meaning that if i want to simply do normal maintenance i will have to run everything for all those in maybe weekly or monthly bases. \\n\\nSo is a bit of a no situation for maintainers, but if you dont maintain your package people will not use it, because there is a concern about how active the project is, even if there are no open issues. For solving both of this things what i have decided is to ad to my CI/CD pipeline a script that runs only on cron jobs from travis ci.\\n\\n```yml\\nos: osx\\nlanguage: node_js\\nnode_js:\\n  - node\\nscript:\\n  - yarn test:cov\\nafter_success:\\n  - if [[ \\"${TRAVIS_EVENT_TYPE}\\" = \\"cron\\" ]]; then ./upgrade.sh; fi\\ndeploy:\\n  skip_cleanup: true\\n  provider: npm\\n  email: $NPM_EMAIL\\n  api_key: $NPM_TOKEN\\n  on:\\n    tags: true\\n```\\n\\nas you can see that is the normal `.travis.yml` for deploying into npm (you will have to define `NPM_EMAIL` and `NPM_TOKEN` as enviroment variables in your build configuration), the main diference is the step after success that if its the cron job going will run the next script.\\n\\n```bash\\n#!/bin/sh\\n\\nset -e\\n\\ngit config --global user.email $GH_EMAIL\\ngit config --global user.name $GH_USER\\n\\ngit remote add origin-master https://${GH_TOKEN}@github.com/${TRAVIS_REPO_SLUG}.git > /dev/null 2>&1\\n\\ngit fetch origin-master\\ngit checkout -b master-local origin-master/master\\n\\nyarn upgrade --latest\\ngit add .\\ngit commit --allow-empty -m \\"updated dependencies [skip ci]\\"\\n\\nyarn test\\nyarn version --patch\\n\\ngit push --quiet origin-master master-local:master\\ngit push --quiet origin-master master-local:master --tags\\n```\\n\\nthis script attaches the current state to a branch makes, upgrades the dependencies and if everything works fine generates a new commit and deploy a patch of the packages (you will have to define `GH_EMAIL`, `GH_USER` and `GH_TOKEN` as environment variables in your build configuration)."},{"id":"/2018/07/04/deploy-hugo-with-travis","metadata":{"permalink":"/blog/2018/07/04/deploy-hugo-with-travis","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2018-07-04-deploy-hugo-with-travis.md","source":"@site/blog/2018-07-04-deploy-hugo-with-travis.md","title":"Create your User/Organization GitHub Page with Hugo + Travis","description":"Create your User/Organization GitHub Page with Hugo + Travis","date":"2018-07-04T00:00:00.000Z","formattedDate":"July 4, 2018","tags":[{"label":"ci","permalink":"/blog/tags/ci"},{"label":"cd","permalink":"/blog/tags/cd"},{"label":"versioning","permalink":"/blog/tags/versioning"},{"label":"travis","permalink":"/blog/tags/travis"},{"label":"travisci","permalink":"/blog/tags/travisci"},{"label":"github","permalink":"/blog/tags/github"}],"readingTime":1.875,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Create your User/Organization GitHub Page with Hugo + Travis","description":"Create your User/Organization GitHub Page with Hugo + Travis","authors":"kanekotic","tags":["ci","cd","versioning","travis","travisci","github"],"draft":false,"published":"2030-08-01T22:00:00.000Z"},"prevItem":{"title":"Update your npm package dependencies and release with Travis","permalink":"/blog/2018/07/11/travis-ci-update-npm-package-dependencies-and-release"},"nextItem":{"title":"C# - Extension methods overlap with linq","permalink":"/blog/2016/01/28/extension-methods-overlap-with-linq"}},"content":"I have just finished migrating my static blog from Hexo to Hugo and one of the main things I care about is to be able to do continuous deployment of my profile and blog. There are quite a few blog posts out there but they are based on using shell scripts and it really becomes a pain to give permissions etc. In the next few lines you will see the simplest way I have found to do this (and is currently as this blog post is being published).\\n\\nYou will need to have:\\n\\n- A Github account.\\n- A Travis CI account.\\n- A Github repository with source code of your web page with Hugo (*1)\\n- A Github repository with the name `<your User or Organization>.github.com` (ex. kanekotic.github.com) (*2).\\n- A developer token from GitHub with commit capabilities (can create in github `Settings -> Developer Settings -> Personal Access Token -> Generate New Token` )\\n\\nI wont cover how to create a Hugo web page as this is best explained in the [quick start](https://gohugo.io/getting-started/quick-start/)) of Hugo.\\n\\nAfter you are happy with the content of your blog in the repository of source code (*1), and want to start deploying you will need to add a `.travis.yml` with the next content\\n\\n```yml\\nsudo: true\\ndist: trusty\\n\\ninstall:\\n  - sudo apt-get --yes install snapd\\n  - sudo snap install hugo\\n\\nscript:\\n  - /snap/bin/hugo \\n\\ndeploy:\\n  provider: pages\\n  local-dir: public\\n  repo: <User or Organization>/<User or Organization>.github.com\\n  target-branch: master\\n  skip-cleanup: true\\n  github-token: $GITHUB_TOKEN\\n  committer-from-gh: true\\n  keep-history: true\\n  on:\\n    branch: master\\n```\\n\\nyou will have to change the repo content to match your destination repository (*2). The previous code what does is installs hugo in the deployment machine, builds your web page and deploys using the pages plugin. If you have a custom domain make sure to set the property `fqdn` to your domain, if not you will overwrite this field in each commit.\\n\\nAfter adding the file you will have to go to Travis web page and toggle your code repository (*1) got to `More Options -> Settings -> Environment Variables` and add `GITHUB_TOKEN` as the token retrieved from github.\\n\\nAfter this in any commit in the master branch of your web page you will get it deployed and go live."},{"id":"/2016/01/28/extension-methods-overlap-with-linq","metadata":{"permalink":"/blog/2016/01/28/extension-methods-overlap-with-linq","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2016-01-28-extension-methods-overlap-with-linq.md","source":"@site/blog/2016-01-28-extension-methods-overlap-with-linq.md","title":"C# - Extension methods overlap with linq","description":"C# - Extension methods overlap with linq","date":"2016-01-28T00:00:00.000Z","formattedDate":"January 28, 2016","tags":[{"label":"daily","permalink":"/blog/tags/daily"},{"label":"learn","permalink":"/blog/tags/learn"}],"readingTime":1.78,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"C# - Extension methods overlap with linq","description":"C# - Extension methods overlap with linq","authors":"kanekotic","tags":["daily","learn"],"draft":false,"published":"2030-08-01T22:00:00.000Z"},"prevItem":{"title":"Create your User/Organization GitHub Page with Hugo + Travis","permalink":"/blog/2018/07/04/deploy-hugo-with-travis"},"nextItem":{"title":"C# - Fluent Interfaces with Extension Methods","permalink":"/blog/2016/01/27/interface-with-extension-methods"}},"content":"I have hit a corner case of extension methods and LINQ. Today I was declaring some extension methods to make my code more readable.So I created an extension method that gets an object and performs a direct cast:\\n\\n```csharp\\npublic static class GeneralExtensions\\n{\\n    public static T Cast<T>(this object o)\\n    {\\n    \\treturn (T)o;\\n    }\\n}\\n```\\n\\nThe intention was to be able to call my direct castings by something like this:\\n```csharp\\nMyObject.CastTo<MyInterface>();\\n```\\n\\nIt happens that in the same namespace I have an extension method that has a LINQ expression\\n```csharp\\nusing System;\\nusing System.Collections.Generic;\\nusing System.Linq;\\n\\npublic static class EnumExtenstions\\n{\\n\\tpublic static IEnumerable<string> UseLinq(this IEnumerable<object> collection)\\n\\t{\\n\\t\\treturn (from object value in collection select value.ToString() ).ToList();\\n\\t}\\n}\\n```\\n\\nAdding this first extension method to my code base cause the next error\\n```\\nError\\tCS1936\\tCould not find an implementation of the query pattern for source type \'object\'.  \'Select\' not found.\\n```\\n\\nHaving both extension methods in different namespaces (and not referred), or rename ```Cast<T>``` to something different solves the issue. This is caused for an overlap of the extension methods where the nearest one to the code is the one called.\\n\\n##**How bad Extension Methods over object could go?**\\n\\nThis is an extract from the answer of Eric Lippert, regarding the code:\\n\\n```csharp\\npublic static class GeneralExtensions\\n{\\n    public static T Cast<T>(this object o)\\n    {\\n    \\treturn (T)o;\\n    }\\n}\\n```\\nSide Effects of the ```cast<T>```:\\n* ```Cast<int>(123)``` unnecessarily boxes the int, ```(int)123``` does not.\\n* ```Cast< short >(123)``` fails but ```(short)123``` succeeds. There is no conversion from a boxed int to a short.\\n* Suppose you have a user-defined conversion from Animal to Shape. ```Cast<Shape>(new Tiger())``` fails but ```(Shape) new Tiger()``` succeeds.\\n* Suppose q is a nullable int that happens to be null. ```Cast<string>(q)``` succeeds! But ```(string)q``` would fail at compile time\\n* Etc\\n\\nCast method has some overlap with the real cast operator but is not a substitute for it. To capture the semantics of the cast operator there is a need to use dynamic, which starts the compiler at runtime and does the compile time analysis on runtime types."},{"id":"/2016/01/27/interface-with-extension-methods","metadata":{"permalink":"/blog/2016/01/27/interface-with-extension-methods","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2016-01-27-interface-with-extension-methods.md","source":"@site/blog/2016-01-27-interface-with-extension-methods.md","title":"C# - Fluent Interfaces with Extension Methods","description":"C# - Fluent Interfaces with Extension Methods","date":"2016-01-27T00:00:00.000Z","formattedDate":"January 27, 2016","tags":[{"label":"daily","permalink":"/blog/tags/daily"},{"label":"learn","permalink":"/blog/tags/learn"}],"readingTime":0.87,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"C# - Fluent Interfaces with Extension Methods","description":"C# - Fluent Interfaces with Extension Methods","authors":"kanekotic","tags":["daily","learn"],"draft":false,"published":"2030-08-01T22:00:00.000Z"},"prevItem":{"title":"C# - Extension methods overlap with linq","permalink":"/blog/2016/01/28/extension-methods-overlap-with-linq"},"nextItem":{"title":"Coding - C# - Complex Constructors","permalink":"/blog/2016/01/26/c-sharp-complex-constructors"}},"content":"I have not experiment to much with fluent interfaces. But is something cool especially to make code that is expressive.\\n\\n```csharp\\npublic struct Coordenates\\n    {\\n        public double X { get; set; }\\n        public double Y { get; set; }\\n        public double Z { get; set; }\\n    }\\n\\n    public static class CoordenatesExtensions\\n    {\\n\\n        public static Coordenates X(this Coordenates coordenates, double value)\\n        {\\n            coordenates.X = value;\\n            return coordenates;\\n        }\\n\\n        public static Coordenates Y(this Coordenates coordenates, double value)\\n        {\\n            coordenates.Y = value;\\n            return coordenates;\\n        }\\n        public static Coordenates Z(this Coordenates coordenates, double value)\\n        {\\n            coordenates.Z = value;\\n            return coordenates;\\n        }\\n    }\\n\\n    public class Points\\n    {\\n        private Coordenates point;\\n        public Points()\\n        {\\n            point = new Coordenates().X(2.1).Y(2.4).Z(3.2);\\n        }\\n    }\\n```\\nalso can be used with some language properties to make it more expressive\\n```csharp\\npublic static class GeneralExtensions\\n{\\n    public static T As<T>(this object o) where T : class\\n    {\\n        return o as T;\\n    }\\n\\n    public static T Cast<T>(this object o)\\n    {\\n        return (T)o;\\n    }\\n\\n    public static bool Is<T>(this object o)\\n    {\\n        return o is T;\\n    }\\n}\\n\\n```"},{"id":"/2016/01/26/c-sharp-complex-constructors","metadata":{"permalink":"/blog/2016/01/26/c-sharp-complex-constructors","editUrl":"https://github.com/kanekotic/kanekotic-page/tree/main/blog/2016-01-26-c-sharp-complex-constructors.md","source":"@site/blog/2016-01-26-c-sharp-complex-constructors.md","title":"Coding - C# - Complex Constructors","description":"Coding - C# - Complex Constructors","date":"2016-01-26T00:00:00.000Z","formattedDate":"January 26, 2016","tags":[{"label":"daily","permalink":"/blog/tags/daily"},{"label":"learn","permalink":"/blog/tags/learn"}],"readingTime":0.985,"hasTruncateMarker":false,"authors":[{"name":"Alvaro Jose","title":"Head of Software @Holaluz","url":"https://github.com/kanekotic","imageURL":"https://github.com/kanekotic.png","key":"kanekotic"}],"frontMatter":{"title":"Coding - C# - Complex Constructors","description":"Coding - C# - Complex Constructors","authors":"kanekotic","tags":["daily","learn"],"draft":false,"published":"2030-08-01T22:00:00.000Z"},"prevItem":{"title":"C# - Fluent Interfaces with Extension Methods","permalink":"/blog/2016/01/27/interface-with-extension-methods"}},"content":"When doing complex objects using an object to help the building is welcome.\\n```csharp\\npublic class Complex\\n{\\n    double x;\\n    double y;\\n    double z;\\n\\n    float height;\\n    float width;\\n\\n    string foreground;\\n    string background;\\n\\n    public Complex()\\n    {\\n        x = 1.456;\\n        y = 1.234;\\n        z = 1.789;\\n\\n        height = 10.12;\\n        width = 10.14;\\n\\n        foreground = \\"#FFF\\";\\n        background = \\"#FA1\\";\\n    }\\n\\n}\\n```\\nIn this way you remove some complexity of just adding steps in your constructor to something more abstract and can contain the logic.\\n\\n```csharp\\npublic class Complex\\n{\\n    public double X { get; set; }\\n    public double Y { get; set; }\\n    public double Z { get; set; }\\n\\n    public double Height { get; set; }\\n    public double Width { get; set; }\\n\\n    public string Foreground { get; set; }\\n    public string Background { get; set; }\\n\\n    public Complex(ComplexBuildHelper buildHelper)\\n    {\\n        buildHelper.Construct(this);\\n    }\\n\\n}\\n\\npublic class ComplexBuildHelper\\n{\\n    public void Construct(Complex reference)\\n    {\\n        BuildPosition(reference);\\n        BuildDimension(reference);\\n        BuildCharacteristics(reference);\\n    }\\n\\n    private void BuildPosition(Complex reference)\\n    {\\n        reference.X = 1.456;\\n        reference.Y = 1.234;\\n        reference.Z = 1.789;\\n    }\\n\\n    private void BuildDimension(Complex reference)\\n    {\\n        reference.Height = 10.12;\\n        reference.Width = 10.14;\\n    }\\n\\n    private void BuildCharacteristics(Complex reference)\\n    {\\n        reference.Foreground = \\"#FFF\\";\\n        reference.Background = \\"#FA1\\";\\n    }\\n}\\n```"}]}')}}]);